{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook will train a very simple model that will compare two numbers and tell us if one is larger than the other.\n",
    "\n",
    "We'll convert the model into something that can be used by tflite and then run it on the ESP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-16 10:01:50.054601: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-16 10:01:50.221030: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-16 10:01:50.221998: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-16 10:01:51.645213: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.data import Dataset\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset to train our model\n",
    "We'll create a python generator and feed that through a tensorflow Dataset to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_generator():\n",
    "    while(True):\n",
    "        number1 = np.random.uniform();\n",
    "        number2 = np.random.uniform();\n",
    "        # our input data is an array containing 2 numbers\n",
    "        X = [number1, number2]\n",
    "        # our label is 1 or 0\n",
    "        Y = 1 if number2 > number1 else 0\n",
    "        # our generator should return the input data and the label\n",
    "        yield X, [Y]\n",
    "        \n",
    "# create a dataset from our generator\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    data_generator, \n",
    "    output_types = (tf.float32, tf.int32),\n",
    "    output_shapes=((2), (1))\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.batch(batch_size=30)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Print the train_dataset\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our very simple mode\n",
    "\n",
    "We don't need a very complicated model for our problem, so we'll just define a small neural network with an input layer and an output layer.\n",
    "\n",
    "It's important that the activation function for the output should be sigmoid. This activation function will output a value between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(2)),\n",
    "    Dense(5, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile our modelÂ¶\n",
    "For our loss function we need to use BinaryCrossentropy.\n",
    "\n",
    "Crossentropy quantifies the difference between two probability distribution.\n",
    "\n",
    "We have a binary distribution (True or False) so we use binary crossentropy to compare the output from our model with the true distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 5)                 15        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 21 (84.00 Byte)\n",
      "Trainable params: 21 (84.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0623 - accuracy: 0.9967\n",
      "Epoch 2/4\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0583 - accuracy: 1.0000\n",
      "Epoch 3/4\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0527 - accuracy: 1.0000\n",
      "Epoch 4/4\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0720 - accuracy: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f19613abfd0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=10,\n",
    "    epochs=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our model\n",
    "We can feed in some values and see what our model predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.91]\n",
      " [0.91]\n",
      " [0.00]\n",
      " [0.00]]\n"
     ]
    }
   ],
   "source": [
    "test_X = np.array([\n",
    "    [0.1, 0.2],\n",
    "    [0.3, 0.4],\n",
    "    [0.5, 0.1],\n",
    "    [0.7, 0.2]\n",
    "])\n",
    "Y = model.predict_on_batch(test_X)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export our model for tflite\n",
    "We need to convert our model into a tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmppjnmdtaz/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmppjnmdtaz/assets\n",
      "/home/milad/milad/1/TEZ/3esp32/2tflight/2tensorflow-lite-esp32/venv/lib/python3.8/site-packages/tensorflow/lite/python/convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2023-07-16 11:11:00.303140: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-07-16 11:11:00.303166: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-07-16 11:11:00.303367: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmppjnmdtaz\n",
      "2023-07-16 11:11:00.304033: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-07-16 11:11:00.304048: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmppjnmdtaz\n",
      "2023-07-16 11:11:00.305932: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-07-16 11:11:00.334878: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmppjnmdtaz\n",
      "2023-07-16 11:11:00.343286: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 39920 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2344"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "def representative_dataset_gen():\n",
    "    for _ in range(10000):\n",
    "        yield [\n",
    "            np.array(\n",
    "                [np.random.uniform(), np.random.uniform()]\n",
    "            , dtype=np.float32)\n",
    "        ]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "tflite_quant_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To convert to C++\n",
    "We can then run this command to convert the model to c code.\n",
    "```\n",
    "xxd -i converted_model.tflite > model_data.cc\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -i converted_model.tflite > firmware/src/model_data1.cc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
