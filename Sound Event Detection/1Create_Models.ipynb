{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fXpFjiht0bg"
      },
      "source": [
        "# Login to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRXsDffet4nW",
        "outputId": "4025b363-40e2-437d-ffd9-b937f28e758d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bikP354nuWkx",
        "outputId": "5274f48b-2797-4bb6-d8d6-d74cbf767095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PUOFcjYhguB"
      },
      "source": [
        "# Fine Tune model for ESC50 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### codes"
      ],
      "metadata": {
        "id": "OgAlm-2cKa7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "5WCn3jQnK0bY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11d4164f-2791-4108-dbc9-00c6470c1aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.10)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as display\n",
        "\n",
        "import glob\n",
        "from collections import Counter\n",
        "\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import soundfile as sf\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import models, transforms\n",
        "import timm\n",
        "\n",
        "import tensorflow as tf\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import datetime\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "def evaluate(model, test_loader, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    num_correct = 0\n",
        "    num_examples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
        "            num_correct += torch.sum(correct).item()\n",
        "            num_examples += correct.shape[0]\n",
        "\n",
        "    accuracy = num_correct / num_examples\n",
        "    return accuracy\n",
        "\n",
        "class FrequencyMask(object):\n",
        "    \"\"\"\n",
        "      Example:\n",
        "        >>> transforms.Compose([\n",
        "        >>>     transforms.ToTensor(),\n",
        "        >>>     FrequencyMask(max_width=10, use_mean=False),\n",
        "        >>> ])\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, max_width, use_mean=True):\n",
        "        self.max_width = max_width\n",
        "        self.use_mean = use_mean\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tensor (Tensor): Tensor image of\n",
        "            size (C, H, W) where the frequency\n",
        "            mask is to be applied.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Transformed image with Frequency Mask.\n",
        "        \"\"\"\n",
        "        start = random.randrange(0, tensor.shape[2])\n",
        "        end = start + random.randrange(1, self.max_width)\n",
        "        if self.use_mean:\n",
        "            tensor[:, start:end, :] = tensor.mean()\n",
        "        else:\n",
        "            tensor[:, start:end, :] = 0\n",
        "        return tensor\n",
        "\n",
        "    def __repr__(self):\n",
        "        format_string = self.__class__.__name__ + \"(max_width=\"\n",
        "        format_string += str(self.max_width) + \")\"\n",
        "        format_string += 'use_mean=' + (str(self.use_mean) + ')')\n",
        "\n",
        "        return format_string\n",
        "\n",
        "\n",
        "class TimeMask(object):\n",
        "    \"\"\"\n",
        "      Example:\n",
        "        >>> transforms.Compose([\n",
        "        >>>     transforms.ToTensor(),\n",
        "        >>>     TimeMask(max_width=10, use_mean=False),\n",
        "        >>> ])\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, max_width, use_mean=True):\n",
        "        self.max_width = max_width\n",
        "        self.use_mean = use_mean\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tensor (Tensor): Tensor image of\n",
        "            size (C, H, W) where the time mask\n",
        "            is to be applied.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Transformed image with Time Mask.\n",
        "        \"\"\"\n",
        "        start = random.randrange(0, tensor.shape[1])\n",
        "        end = start + random.randrange(0, self.max_width)\n",
        "        if self.use_mean:\n",
        "            tensor[:, :, start:end] = tensor.mean()\n",
        "        else:\n",
        "            tensor[:, :, start:end] = 0\n",
        "        return tensor\n",
        "\n",
        "    def __repr__(self):\n",
        "        format_string = self.__class__.__name__ + \"(max_width=\"\n",
        "        format_string += str(self.max_width) + \")\"\n",
        "        format_string += 'use_mean=' + (str(self.use_mean) + ')')\n",
        "        return format_string\n",
        "\n",
        "\n",
        "class PrecomputedESC50(Dataset):\n",
        "    def __init__(self,path, max_freqmask_width, max_timemask_width, use_mean=True, dpi=50):\n",
        "        files = Path(path).glob('*.png')\n",
        "        self.items = [(f,int(f.name.split(\"-\")[-1].replace(\".wav.png\",\"\"))) for f in files]\n",
        "        self.length = len(self.items)\n",
        "        self.max_freqmask_width = max_freqmask_width\n",
        "        self.max_timemask_width = max_timemask_width\n",
        "        self.use_mean = use_mean\n",
        "        self.img_transforms = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
        "            transforms.RandomApply([FrequencyMask(self.max_freqmask_width, self.use_mean)], p=0.5),\n",
        "            transforms.RandomApply([TimeMask(self.max_timemask_width, self.use_mean)], p=0.5)])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename, label = self.items[index]\n",
        "        img = Image.open(filename).convert('RGB')\n",
        "        return (self.img_transforms(img), label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "# Define a function to plot and log confusion matrix to TensorBoard\n",
        "def plot_confusion_matrix(model, test_loader, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            predictions = torch.max(F.softmax(output, dim=1), dim=1)[1].cpu().numpy()\n",
        "            all_predictions.extend(predictions)\n",
        "            all_labels.extend(targets.cpu().numpy())\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "    # Create a heatmap of the confusion matrix\n",
        "    plt.figure(figsize=(20, 16))\n",
        "    sn.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=True, yticklabels=True)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "\n",
        "    figure = plt.gcf()\n",
        "    return figure\n",
        "\n",
        "# Define a function to log predictions vs. actuals as images to TensorBoard\n",
        "def log_predictions_vs_actuals(model, data_loader, device=\"cpu\", num_batches=5):\n",
        "    model.eval()\n",
        "\n",
        "    batch_counter = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            if batch_counter >= num_batches:\n",
        "                break\n",
        "\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            predictions = torch.max(F.softmax(output, dim=1), dim=1)\n",
        "            predicted_labels = predictions[1]\n",
        "            probabilities = predictions[0]\n",
        "\n",
        "            # Convert PyTorch tensors to NumPy arrays\n",
        "            inputs_np = inputs.permute(0, 2, 3, 1).cpu().numpy()\n",
        "\n",
        "            # Create a figure for each batch\n",
        "            fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(12, 12))\n",
        "\n",
        "            for i, ax in enumerate(axes.flat):\n",
        "                ax.imshow(inputs_np[i])\n",
        "                ax.axis(\"off\")\n",
        "\n",
        "                actual_label = targets[i].item()\n",
        "                predicted_label = predicted_labels[i].item()\n",
        "                probability = probabilities[i].item()\n",
        "\n",
        "                # Color the title based on correctness\n",
        "                title_color = 'green' if actual_label == predicted_label else 'red'\n",
        "\n",
        "                ax.set_title(f\"Actual: {actual_label}\\nPredicted: {predicted_label}\\nProb: {probability:.2f}\", color=title_color)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            batch_counter += 1\n",
        "    return fig\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience, verbose=False):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_valid_accuracy = 0.0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def step(self, valid_accuracy):\n",
        "        if valid_accuracy > self.best_valid_accuracy:\n",
        "            self.best_valid_accuracy = valid_accuracy\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter > self.patience:\n",
        "                self.early_stop = True\n",
        "                if self.verbose:\n",
        "                    print(\"Early stopping activated.\")\n",
        "        return self.early_stop\n",
        "\n",
        "class LearningRateScheduler(lr_scheduler._LRScheduler):\n",
        "    def __init__(self, optimizer, patience, factor=0.1, verbose=False):\n",
        "        self.optimizer = optimizer\n",
        "        self.patience = patience\n",
        "        self.factor = factor\n",
        "        self.verbose = verbose\n",
        "        self.lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=self.patience, factor=self.factor, verbose=self.verbose)\n",
        "\n",
        "    def step(self, valid_accuracy):\n",
        "        self.lr_scheduler.step(valid_accuracy)\n",
        "        return self.optimizer.param_groups[0]['lr']\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "PATH_ESC50_TRAIN=\"./train1/\"\n",
        "PATH_ESC50_VALID=\"./valid1/\"\n",
        "PATH_ESC50_TEST=\"./test/\"\n",
        "\n",
        "bs=16\n",
        "esc50pre_train = PrecomputedESC50(PATH_ESC50_TRAIN, max_freqmask_width=10, max_timemask_width=10 )\n",
        "esc50pre_valid = PrecomputedESC50(PATH_ESC50_VALID,max_freqmask_width=10, max_timemask_width=10 )\n",
        "esc50pre_test = PrecomputedESC50(PATH_ESC50_TEST,max_freqmask_width=10, max_timemask_width=10 )\n",
        "\n",
        "esc50_train_loader = torch.utils.data.DataLoader(esc50pre_train, bs, shuffle=True)\n",
        "esc50_val_loader = torch.utils.data.DataLoader(esc50pre_valid, bs, shuffle=True)\n",
        "esc50_test_loader = torch.utils.data.DataLoader(esc50pre_test, bs, shuffle=True)"
      ],
      "metadata": {
        "id": "fYEaGQ82KdIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EnvNet V2"
      ],
      "metadata": {
        "id": "qiGsIvMZFFr5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqGyGJ-UvAlD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "025eeb8c-f574-4628-f66c-0e90145c3930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.10-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.19.0 safetensors-0.4.0 timm-0.9.10\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "660244b55b3c4d928c2258026b94ffaf",
            "f3649c7014604e919f985460ddbb5b26",
            "8b5e120de2eb4f239730075c838cf5e3",
            "d3fa438ead2e484ea415013088a84c8c",
            "36932f9df1804233ba999b7ec0d646b1",
            "f51d3c4a6f374579bade968bc3fb749c",
            "dcb173e5850e4757bc7ea461e13acb62",
            "a6ab51e8a2fb4a71967b57984fc7e8bf",
            "45d1ea6681c445af8c8937d1a165cba3",
            "224f3eb4eee8451aa9ba52151163032c",
            "da85508890414047aee3d9a6b0566c5c"
          ]
        },
        "id": "HZs0_Oqrx6z1",
        "outputId": "7e939f13-7113-4d43-afdd-67593910b1ed"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "660244b55b3c4d928c2258026b94ffaf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/57.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Learning Rate: 0.01, Training Loss: 3.74, Training Accuracy: 0.08, Validation Loss: 3.52, Validation Accuracy: 0.23\n",
            "Epoch: 2, Learning Rate: 0.01, Training Loss: 3.12, Training Accuracy: 0.32, Validation Loss: 2.92, Validation Accuracy: 0.46\n",
            "Epoch: 3, Learning Rate: 0.01, Training Loss: 2.48, Training Accuracy: 0.53, Validation Loss: 2.29, Validation Accuracy: 0.59\n",
            "Epoch: 4, Learning Rate: 0.01, Training Loss: 1.92, Training Accuracy: 0.67, Validation Loss: 1.83, Validation Accuracy: 0.66\n",
            "Epoch: 5, Learning Rate: 0.01, Training Loss: 1.42, Training Accuracy: 0.80, Validation Loss: 1.47, Validation Accuracy: 0.72\n",
            "Epoch: 6, Learning Rate: 0.01, Training Loss: 1.07, Training Accuracy: 0.86, Validation Loss: 1.27, Validation Accuracy: 0.74\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-03.\n",
            "Epoch 00007: reducing learning rate of group 1 to 1.0000e-03.\n",
            "Epoch 00007: reducing learning rate of group 2 to 1.0000e-05.\n",
            "Epoch 00007: reducing learning rate of group 3 to 1.0000e-05.\n",
            "Epoch 00007: reducing learning rate of group 4 to 1.0000e-05.\n",
            "Epoch 00007: reducing learning rate of group 5 to 1.0000e-05.\n",
            "Epoch: 7, Learning Rate: 0.001, Training Loss: 0.80, Training Accuracy: 0.91, Validation Loss: 1.09, Validation Accuracy: 0.77\n",
            "Epoch: 8, Learning Rate: 0.001, Training Loss: 0.59, Training Accuracy: 0.95, Validation Loss: 1.01, Validation Accuracy: 0.78\n",
            "Epoch: 9, Learning Rate: 0.001, Training Loss: 0.54, Training Accuracy: 0.96, Validation Loss: 0.97, Validation Accuracy: 0.79\n",
            "Epoch: 10, Learning Rate: 0.001, Training Loss: 0.52, Training Accuracy: 0.96, Validation Loss: 0.96, Validation Accuracy: 0.80\n",
            "Epoch: 11, Learning Rate: 0.001, Training Loss: 0.45, Training Accuracy: 0.97, Validation Loss: 0.94, Validation Accuracy: 0.80\n",
            "Epoch: 12, Learning Rate: 0.001, Training Loss: 0.48, Training Accuracy: 0.96, Validation Loss: 0.92, Validation Accuracy: 0.80\n",
            "Epoch 00013: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 00013: reducing learning rate of group 1 to 1.0000e-04.\n",
            "Epoch 00013: reducing learning rate of group 2 to 1.0000e-06.\n",
            "Epoch 00013: reducing learning rate of group 3 to 1.0000e-06.\n",
            "Epoch 00013: reducing learning rate of group 4 to 1.0000e-06.\n",
            "Epoch 00013: reducing learning rate of group 5 to 1.0000e-06.\n",
            "Epoch: 13, Learning Rate: 0.0001, Training Loss: 0.44, Training Accuracy: 0.97, Validation Loss: 0.92, Validation Accuracy: 0.80\n",
            "Epoch: 14, Learning Rate: 0.0001, Training Loss: 0.43, Training Accuracy: 0.97, Validation Loss: 0.91, Validation Accuracy: 0.79\n",
            "Epoch: 15, Learning Rate: 0.0001, Training Loss: 0.40, Training Accuracy: 0.98, Validation Loss: 0.91, Validation Accuracy: 0.79\n",
            "Epoch: 16, Learning Rate: 0.0001, Training Loss: 0.43, Training Accuracy: 0.97, Validation Loss: 0.89, Validation Accuracy: 0.80\n",
            "Epoch: 17, Learning Rate: 0.0001, Training Loss: 0.40, Training Accuracy: 0.98, Validation Loss: 0.92, Validation Accuracy: 0.79\n",
            "Epoch: 18, Learning Rate: 0.0001, Training Loss: 0.39, Training Accuracy: 0.98, Validation Loss: 0.92, Validation Accuracy: 0.81\n",
            "Epoch 00019: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch 00019: reducing learning rate of group 1 to 1.0000e-05.\n",
            "Epoch 00019: reducing learning rate of group 2 to 1.0000e-07.\n",
            "Epoch 00019: reducing learning rate of group 3 to 1.0000e-07.\n",
            "Epoch 00019: reducing learning rate of group 4 to 1.0000e-07.\n",
            "Epoch 00019: reducing learning rate of group 5 to 1.0000e-07.\n",
            "Epoch: 19, Learning Rate: 1e-05, Training Loss: 0.41, Training Accuracy: 0.97, Validation Loss: 0.91, Validation Accuracy: 0.80\n",
            "Epoch: 20, Learning Rate: 1e-05, Training Loss: 0.41, Training Accuracy: 0.98, Validation Loss: 0.92, Validation Accuracy: 0.79\n",
            "Epoch: 21, Learning Rate: 1e-05, Training Loss: 0.42, Training Accuracy: 0.98, Validation Loss: 0.90, Validation Accuracy: 0.80\n",
            "Epoch: 23, Learning Rate: 1e-05, Training Loss: 0.39, Training Accuracy: 0.98, Validation Loss: 0.92, Validation Accuracy: 0.80\n",
            "Epoch: 24, Learning Rate: 1e-05, Training Loss: 0.39, Training Accuracy: 0.98, Validation Loss: 0.93, Validation Accuracy: 0.78\n",
            "Epoch 00025: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch 00025: reducing learning rate of group 1 to 1.0000e-06.\n",
            "Epoch 00025: reducing learning rate of group 2 to 1.0000e-08.\n",
            "Epoch 00025: reducing learning rate of group 3 to 1.0000e-08.\n",
            "Epoch 00025: reducing learning rate of group 4 to 1.0000e-08.\n",
            "Epoch 00025: reducing learning rate of group 5 to 1.0000e-08.\n",
            "Epoch: 25, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.42, Training Accuracy: 0.97, Validation Loss: 0.90, Validation Accuracy: 0.80\n",
            "Epoch: 26, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.39, Training Accuracy: 0.98, Validation Loss: 0.93, Validation Accuracy: 0.79\n",
            "Epoch: 27, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.41, Training Accuracy: 0.98, Validation Loss: 0.92, Validation Accuracy: 0.80\n",
            "Epoch: 28, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.41, Training Accuracy: 0.98, Validation Loss: 0.89, Validation Accuracy: 0.81\n",
            "Epoch: 29, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.41, Training Accuracy: 0.98, Validation Loss: 0.90, Validation Accuracy: 0.79\n",
            "Early stopping activated.\n",
            "\n",
            " Model has been saved to tensorboard_logs/2023-11-11_141556_tf_efficientnetv2_b3/best_model_tf_efficientnetv2_b3.pth\n",
            "\n",
            " Test Accuracy: 80.25%\n"
          ]
        }
      ],
      "source": [
        "import IPython.display as display\n",
        "\n",
        "import glob\n",
        "from collections import Counter\n",
        "\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import soundfile as sf\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import models, transforms\n",
        "import timm\n",
        "\n",
        "import tensorflow as tf\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import datetime\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "def evaluate(model, test_loader, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    num_correct = 0\n",
        "    num_examples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
        "            num_correct += torch.sum(correct).item()\n",
        "            num_examples += correct.shape[0]\n",
        "\n",
        "    accuracy = num_correct / num_examples\n",
        "    return accuracy\n",
        "\n",
        "class FrequencyMask(object):\n",
        "    \"\"\"\n",
        "      Example:\n",
        "        >>> transforms.Compose([\n",
        "        >>>     transforms.ToTensor(),\n",
        "        >>>     FrequencyMask(max_width=10, use_mean=False),\n",
        "        >>> ])\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, max_width, use_mean=True):\n",
        "        self.max_width = max_width\n",
        "        self.use_mean = use_mean\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tensor (Tensor): Tensor image of\n",
        "            size (C, H, W) where the frequency\n",
        "            mask is to be applied.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Transformed image with Frequency Mask.\n",
        "        \"\"\"\n",
        "        start = random.randrange(0, tensor.shape[2])\n",
        "        end = start + random.randrange(1, self.max_width)\n",
        "        if self.use_mean:\n",
        "            tensor[:, start:end, :] = tensor.mean()\n",
        "        else:\n",
        "            tensor[:, start:end, :] = 0\n",
        "        return tensor\n",
        "\n",
        "    def __repr__(self):\n",
        "        format_string = self.__class__.__name__ + \"(max_width=\"\n",
        "        format_string += str(self.max_width) + \")\"\n",
        "        format_string += 'use_mean=' + (str(self.use_mean) + ')')\n",
        "\n",
        "        return format_string\n",
        "\n",
        "\n",
        "class TimeMask(object):\n",
        "    \"\"\"\n",
        "      Example:\n",
        "        >>> transforms.Compose([\n",
        "        >>>     transforms.ToTensor(),\n",
        "        >>>     TimeMask(max_width=10, use_mean=False),\n",
        "        >>> ])\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, max_width, use_mean=True):\n",
        "        self.max_width = max_width\n",
        "        self.use_mean = use_mean\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tensor (Tensor): Tensor image of\n",
        "            size (C, H, W) where the time mask\n",
        "            is to be applied.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Transformed image with Time Mask.\n",
        "        \"\"\"\n",
        "        start = random.randrange(0, tensor.shape[1])\n",
        "        end = start + random.randrange(0, self.max_width)\n",
        "        if self.use_mean:\n",
        "            tensor[:, :, start:end] = tensor.mean()\n",
        "        else:\n",
        "            tensor[:, :, start:end] = 0\n",
        "        return tensor\n",
        "\n",
        "    def __repr__(self):\n",
        "        format_string = self.__class__.__name__ + \"(max_width=\"\n",
        "        format_string += str(self.max_width) + \")\"\n",
        "        format_string += 'use_mean=' + (str(self.use_mean) + ')')\n",
        "        return format_string\n",
        "\n",
        "\n",
        "class PrecomputedESC50(Dataset):\n",
        "    def __init__(self,path, max_freqmask_width, max_timemask_width, use_mean=True, dpi=50):\n",
        "        files = Path(path).glob('*.png')\n",
        "        self.items = [(f,int(f.name.split(\"-\")[-1].replace(\".wav.png\",\"\"))) for f in files]\n",
        "        self.length = len(self.items)\n",
        "        self.max_freqmask_width = max_freqmask_width\n",
        "        self.max_timemask_width = max_timemask_width\n",
        "        self.use_mean = use_mean\n",
        "        self.img_transforms = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
        "            transforms.RandomApply([FrequencyMask(self.max_freqmask_width, self.use_mean)], p=0.5),\n",
        "            transforms.RandomApply([TimeMask(self.max_timemask_width, self.use_mean)], p=0.5)])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename, label = self.items[index]\n",
        "        img = Image.open(filename).convert('RGB')\n",
        "        return (self.img_transforms(img), label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "# Define a function to plot and log confusion matrix to TensorBoard\n",
        "def plot_confusion_matrix(model, test_loader, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            predictions = torch.max(F.softmax(output, dim=1), dim=1)[1].cpu().numpy()\n",
        "            all_predictions.extend(predictions)\n",
        "            all_labels.extend(targets.cpu().numpy())\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "    # Create a heatmap of the confusion matrix\n",
        "    plt.figure(figsize=(20, 16))\n",
        "    sn.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=True, yticklabels=True)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "\n",
        "    figure = plt.gcf()\n",
        "    return figure\n",
        "\n",
        "# Define a function to log predictions vs. actuals as images to TensorBoard\n",
        "def log_predictions_vs_actuals(model, data_loader, device=\"cpu\", num_batches=5):\n",
        "    model.eval()\n",
        "\n",
        "    batch_counter = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            if batch_counter >= num_batches:\n",
        "                break\n",
        "\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            predictions = torch.max(F.softmax(output, dim=1), dim=1)\n",
        "            predicted_labels = predictions[1]\n",
        "            probabilities = predictions[0]\n",
        "\n",
        "            # Convert PyTorch tensors to NumPy arrays\n",
        "            inputs_np = inputs.permute(0, 2, 3, 1).cpu().numpy()\n",
        "\n",
        "            # Create a figure for each batch\n",
        "            fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(12, 12))\n",
        "\n",
        "            for i, ax in enumerate(axes.flat):\n",
        "                ax.imshow(inputs_np[i])\n",
        "                ax.axis(\"off\")\n",
        "\n",
        "                actual_label = targets[i].item()\n",
        "                predicted_label = predicted_labels[i].item()\n",
        "                probability = probabilities[i].item()\n",
        "\n",
        "                # Color the title based on correctness\n",
        "                title_color = 'green' if actual_label == predicted_label else 'red'\n",
        "\n",
        "                ax.set_title(f\"Actual: {actual_label}\\nPredicted: {predicted_label}\\nProb: {probability:.2f}\", color=title_color)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            batch_counter += 1\n",
        "    return fig\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience, verbose=False):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_valid_accuracy = 0.0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def step(self, valid_accuracy):\n",
        "        if valid_accuracy > self.best_valid_accuracy:\n",
        "            self.best_valid_accuracy = valid_accuracy\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter > self.patience:\n",
        "                self.early_stop = True\n",
        "                if self.verbose:\n",
        "                    print(\"Early stopping activated.\")\n",
        "        return self.early_stop\n",
        "\n",
        "class LearningRateScheduler(lr_scheduler._LRScheduler):\n",
        "    def __init__(self, optimizer, patience, factor=0.1, verbose=False):\n",
        "        self.optimizer = optimizer\n",
        "        self.patience = patience\n",
        "        self.factor = factor\n",
        "        self.verbose = verbose\n",
        "        self.lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=self.patience, factor=self.factor, verbose=self.verbose)\n",
        "\n",
        "    def step(self, valid_accuracy):\n",
        "        self.lr_scheduler.step(valid_accuracy)\n",
        "        return self.optimizer.param_groups[0]['lr']\n",
        "\n",
        "\n",
        "# Create a directory to store TensorBoard logs\n",
        "log_dir = 'tensorboard_logs'\n",
        "\n",
        "# Create a TensorBoard SummaryWriter\n",
        "load_model_name = \"tf_efficientnetv2_b3\"\n",
        "model_name = \"best_model_\" + load_model_name + \".pth\"\n",
        "\n",
        "current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
        "unique_folder_name = f\"{current_datetime}_{load_model_name}\"\n",
        "unique_log_dir = os.path.join(log_dir, unique_folder_name)\n",
        "\n",
        "layout = {\n",
        "    \"Train and validation at same time\": {\n",
        "        \"Loss\": [\"Multiline\", [\"Loss/Train\", \"Loss/Validation\"]],\n",
        "        \"Accuracy\": [\"Multiline\", [\"Accuracy/Train\", \"Accuracy/Validation\"]],\n",
        "    },\n",
        "}\n",
        "\n",
        "writer = SummaryWriter(log_dir=unique_log_dir)\n",
        "writer.add_custom_scalars(layout)\n",
        "\n",
        "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
        "    best_valid_accuracy = 0.0\n",
        "    best_model_state = None\n",
        "\n",
        "    # Save the model next to the log file\n",
        "    model_path = os.path.join(unique_log_dir, model_name)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        training_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        model.train()\n",
        "\n",
        "        # Initialize variables for train accuracy calculation\n",
        "        num_correct_train = 0\n",
        "        num_examples_train = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            loss = loss_fn(output, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            training_loss += loss.data.item() * inputs.size(0)\n",
        "\n",
        "            # Calculate the number of correct predictions in the current batch\n",
        "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
        "            num_correct_train += torch.sum(correct).item()\n",
        "            num_examples_train += correct.shape[0]\n",
        "\n",
        "        training_loss /= len(train_loader.dataset)\n",
        "        train_accuracy = num_correct_train / num_examples_train\n",
        "\n",
        "        model.eval()\n",
        "        num_correct = 0\n",
        "        num_examples = 0\n",
        "\n",
        "        for batch in val_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            output = model(inputs)\n",
        "            targets = targets.to(device)\n",
        "            loss = loss_fn(output, targets)\n",
        "            valid_loss += loss.data.item() * inputs.size(0)\n",
        "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
        "\n",
        "            num_correct += torch.sum(correct).item()\n",
        "            num_examples += correct.shape[0]\n",
        "\n",
        "        valid_loss /= len(val_loader.dataset)\n",
        "        valid_accuracy = num_correct / num_examples\n",
        "\n",
        "        # Get the current learning rate from the optimizer\n",
        "        current_lr = lr_scheduler.step(valid_accuracy)\n",
        "\n",
        "        print('Epoch: {}, Learning Rate: {}, Training Loss: {:.2f}, Training Accuracy: {:.2f}, Validation Loss: {:.2f}, Validation Accuracy: {:.2f}'.format(epoch, current_lr, training_loss, train_accuracy, valid_loss, valid_accuracy))\n",
        "\n",
        "        # Log training accuracy to TensorBoard\n",
        "        writer.add_scalar('Learning Rate', current_lr, epoch)\n",
        "        writer.add_scalar('Loss/Train', training_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/Train', train_accuracy, epoch)\n",
        "        writer.add_scalar('Loss/Validation', valid_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/Validation', valid_accuracy, epoch)\n",
        "\n",
        "        early_stop = early_stopping.step(valid_accuracy)\n",
        "        if early_stop:\n",
        "            break  # Stop training if early stopping is activated\n",
        "\n",
        "        # Save the best model based on validation accuracy\n",
        "        if valid_accuracy > best_valid_accuracy:\n",
        "            best_valid_accuracy = valid_accuracy\n",
        "            best_model_state = model.state_dict()\n",
        "            # Save the best model state to a file\n",
        "            torch.save(best_model_state, model_path)\n",
        "\n",
        "    print(f\"\\n Model has been saved to {model_path}\")\n",
        "\n",
        "    # Inspect the model\n",
        "    writer.add_graph(model, inputs)\n",
        "    writer.add_figure('Confusion Matrix', plot_confusion_matrix(model, val_loader, device))\n",
        "    # writer.add_figure(f\"Predictions vs. Actuals\", log_predictions_vs_actuals(model, val_loader, device=device, num_batches=1))\n",
        "\n",
        "    # Close the TensorBoard SummaryWriter\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "PATH_ESC50_TRAIN=\"./train1/\"\n",
        "PATH_ESC50_VALID=\"./valid1/\"\n",
        "PATH_ESC50_TEST=\"./test/\"\n",
        "\n",
        "bs=16\n",
        "esc50pre_train = PrecomputedESC50(PATH_ESC50_TRAIN, max_freqmask_width=10, max_timemask_width=10 )\n",
        "esc50pre_valid = PrecomputedESC50(PATH_ESC50_VALID,max_freqmask_width=10, max_timemask_width=10 )\n",
        "esc50pre_test = PrecomputedESC50(PATH_ESC50_TEST,max_freqmask_width=10, max_timemask_width=10 )\n",
        "\n",
        "esc50_train_loader = torch.utils.data.DataLoader(esc50pre_train, bs, shuffle=True)\n",
        "esc50_val_loader = torch.utils.data.DataLoader(esc50pre_valid, bs, shuffle=True)\n",
        "esc50_test_loader = torch.utils.data.DataLoader(esc50pre_test, bs, shuffle=True)\n",
        "\n",
        "#model = models.resnet50(pretrained=True)\n",
        "model= timm.create_model(load_model_name, pretrained=True)\n",
        "model.classifier = nn.Sequential(nn.Linear(model.classifier.in_features,500),\n",
        "                               nn.ReLU(),\n",
        "                               nn.Dropout(),\n",
        "                               nn.Linear(500,50))\n",
        "\n",
        "lr = 1e-2\n",
        "model.to(device)\n",
        "# torch.save(model.state_dict(), \"model.pth\")\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# model.load_state_dict(torch.load(\"model.pth\"))\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "                        {'params': model.conv_stem.parameters()},\n",
        "                        {'params': model.bn1.parameters()},\n",
        "                        # {'params': model.act.parameters()},\n",
        "                        {'params': model.blocks.parameters(),'lr': 1e-4},\n",
        "                        {'params': model.conv_head.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.bn2.parameters(), 'lr': 1e-4},\n",
        "                        # {'params': model.act2.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.global_pool.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.classifier.parameters(), 'lr': 1e-8}\n",
        "                        ], lr=1e-2)\n",
        "\n",
        "# Use these classes during training\n",
        "patience = 5\n",
        "early_stopping_patience=2*patience\n",
        "early_stopping = EarlyStopping(patience=early_stopping_patience, verbose=True)\n",
        "lr_scheduler = LearningRateScheduler(optimizer, patience=patience, factor=0.1, verbose=True)\n",
        "\n",
        "train(model, optimizer, nn.CrossEntropyLoss(), esc50_train_loader, esc50_val_loader, epochs=50, device=device)\n",
        "\n",
        "test_accuracy = evaluate(model, esc50_test_loader, device=device)\n",
        "print(f\"\\n Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KjcVH_Mfz59P"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZASkq00Oz59Q",
        "outputId": "069e6224-2642-4ee4-abee-93bf6bda9c5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-10_120231_tf_efficientnetv2_b3\t2023-11-10_123852_tf_efficientnetv2_b3\n",
            "2023-11-10_123147_tf_efficientnetv2_b3\t2023-11-11_051023_tf_efficientnetv2_b3\n"
          ]
        }
      ],
      "source": [
        "!ls tensorboard_logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "td2XUXXnz59R"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir tensorboard_logs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet 50"
      ],
      "metadata": {
        "id": "HdXoPy1LFQV4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "025eeb8c-f574-4628-f66c-0e90145c3930",
        "id": "EDuDL4UPFQV4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.10-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.19.0 safetensors-0.4.0 timm-0.9.10\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c4cea99-f6e0-4dbe-e40b-fea7017249c4",
        "id": "kt5FS6gVFQV5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 165MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Learning Rate: 0.0001, Training Loss: 3.60, Training Accuracy: 0.17, Validation Loss: 3.06, Validation Accuracy: 0.35\n",
            "Epoch: 2, Learning Rate: 0.0001, Training Loss: 2.97, Training Accuracy: 0.42, Validation Loss: 2.52, Validation Accuracy: 0.49\n",
            "Epoch: 3, Learning Rate: 0.0001, Training Loss: 2.41, Training Accuracy: 0.59, Validation Loss: 2.05, Validation Accuracy: 0.64\n",
            "Epoch: 4, Learning Rate: 0.0001, Training Loss: 1.97, Training Accuracy: 0.73, Validation Loss: 1.70, Validation Accuracy: 0.67\n",
            "Epoch: 5, Learning Rate: 0.0001, Training Loss: 1.55, Training Accuracy: 0.82, Validation Loss: 1.68, Validation Accuracy: 0.68\n",
            "Epoch: 6, Learning Rate: 0.0001, Training Loss: 1.23, Training Accuracy: 0.90, Validation Loss: 1.33, Validation Accuracy: 0.77\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch 00007: reducing learning rate of group 1 to 1.0000e-05.\n",
            "Epoch 00007: reducing learning rate of group 2 to 1.0000e-05.\n",
            "Epoch 00007: reducing learning rate of group 3 to 1.0000e-05.\n",
            "Epoch 00007: reducing learning rate of group 4 to 1.0000e-05.\n",
            "Epoch: 7, Learning Rate: 1e-05, Training Loss: 1.01, Training Accuracy: 0.92, Validation Loss: 1.33, Validation Accuracy: 0.76\n",
            "Epoch: 8, Learning Rate: 1e-05, Training Loss: 0.76, Training Accuracy: 0.97, Validation Loss: 0.99, Validation Accuracy: 0.83\n",
            "Epoch: 9, Learning Rate: 1e-05, Training Loss: 0.69, Training Accuracy: 0.98, Validation Loss: 0.99, Validation Accuracy: 0.82\n",
            "Epoch: 10, Learning Rate: 1e-05, Training Loss: 0.67, Training Accuracy: 0.98, Validation Loss: 0.95, Validation Accuracy: 0.84\n",
            "Epoch: 11, Learning Rate: 1e-05, Training Loss: 0.61, Training Accuracy: 0.99, Validation Loss: 0.98, Validation Accuracy: 0.84\n",
            "Epoch: 12, Learning Rate: 1e-05, Training Loss: 0.61, Training Accuracy: 0.98, Validation Loss: 0.95, Validation Accuracy: 0.83\n",
            "Epoch 00013: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch 00013: reducing learning rate of group 1 to 1.0000e-06.\n",
            "Epoch 00013: reducing learning rate of group 2 to 1.0000e-06.\n",
            "Epoch 00013: reducing learning rate of group 3 to 1.0000e-06.\n",
            "Epoch 00013: reducing learning rate of group 4 to 1.0000e-06.\n",
            "Epoch: 13, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.59, Training Accuracy: 0.99, Validation Loss: 0.91, Validation Accuracy: 0.85\n",
            "Epoch: 14, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.57, Training Accuracy: 0.99, Validation Loss: 0.90, Validation Accuracy: 0.84\n",
            "Epoch: 15, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.55, Training Accuracy: 0.99, Validation Loss: 0.92, Validation Accuracy: 0.84\n",
            "Epoch: 16, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.57, Training Accuracy: 0.99, Validation Loss: 0.94, Validation Accuracy: 0.84\n",
            "Epoch: 17, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.55, Training Accuracy: 0.99, Validation Loss: 0.93, Validation Accuracy: 0.83\n",
            "Epoch: 18, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.54, Training Accuracy: 0.99, Validation Loss: 0.91, Validation Accuracy: 0.84\n",
            "Epoch 00019: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Epoch 00019: reducing learning rate of group 1 to 1.0000e-07.\n",
            "Epoch 00019: reducing learning rate of group 2 to 1.0000e-07.\n",
            "Epoch 00019: reducing learning rate of group 3 to 1.0000e-07.\n",
            "Epoch 00019: reducing learning rate of group 4 to 1.0000e-07.\n",
            "Epoch: 19, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.54, Training Accuracy: 0.99, Validation Loss: 0.95, Validation Accuracy: 0.84\n",
            "Epoch: 20, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.54, Training Accuracy: 0.99, Validation Loss: 0.90, Validation Accuracy: 0.85\n",
            "Epoch: 21, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.55, Training Accuracy: 0.99, Validation Loss: 0.91, Validation Accuracy: 0.85\n",
            "Epoch: 22, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.54, Training Accuracy: 0.99, Validation Loss: 0.92, Validation Accuracy: 0.83\n",
            "Epoch: 23, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.54, Training Accuracy: 0.99, Validation Loss: 0.91, Validation Accuracy: 0.85\n",
            "Epoch: 24, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.55, Training Accuracy: 0.99, Validation Loss: 0.92, Validation Accuracy: 0.84\n",
            "Epoch 00025: reducing learning rate of group 0 to 1.0000e-08.\n",
            "Epoch 00025: reducing learning rate of group 1 to 1.0000e-08.\n",
            "Epoch 00025: reducing learning rate of group 2 to 1.0000e-08.\n",
            "Epoch 00025: reducing learning rate of group 3 to 1.0000e-08.\n",
            "Epoch 00025: reducing learning rate of group 4 to 1.0000e-08.\n",
            "Epoch: 25, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.53, Training Accuracy: 0.99, Validation Loss: 0.94, Validation Accuracy: 0.84\n",
            "Epoch: 26, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.54, Training Accuracy: 0.99, Validation Loss: 0.89, Validation Accuracy: 0.85\n",
            "Epoch: 27, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.53, Training Accuracy: 0.99, Validation Loss: 0.90, Validation Accuracy: 0.85\n",
            "Epoch: 28, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.54, Training Accuracy: 0.99, Validation Loss: 0.91, Validation Accuracy: 0.84\n",
            "Epoch: 29, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.54, Training Accuracy: 0.99, Validation Loss: 0.91, Validation Accuracy: 0.84\n",
            "Epoch: 30, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.55, Training Accuracy: 0.99, Validation Loss: 0.91, Validation Accuracy: 0.86\n",
            "Epoch: 31, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.52, Training Accuracy: 1.00, Validation Loss: 0.91, Validation Accuracy: 0.84\n",
            "Epoch: 32, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.54, Training Accuracy: 0.99, Validation Loss: 0.91, Validation Accuracy: 0.85\n",
            "Epoch: 33, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.54, Training Accuracy: 0.99, Validation Loss: 0.91, Validation Accuracy: 0.85\n",
            "Epoch: 34, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.53, Training Accuracy: 0.99, Validation Loss: 0.92, Validation Accuracy: 0.83\n",
            "Epoch: 35, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.52, Training Accuracy: 0.99, Validation Loss: 0.92, Validation Accuracy: 0.83\n",
            "Epoch: 36, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.53, Training Accuracy: 0.99, Validation Loss: 0.90, Validation Accuracy: 0.85\n",
            "Epoch: 37, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.54, Training Accuracy: 0.99, Validation Loss: 0.90, Validation Accuracy: 0.85\n",
            "Epoch: 38, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.53, Training Accuracy: 0.99, Validation Loss: 0.94, Validation Accuracy: 0.83\n",
            "Epoch: 39, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.52, Training Accuracy: 0.99, Validation Loss: 0.91, Validation Accuracy: 0.86\n",
            "Epoch: 40, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.53, Training Accuracy: 0.99, Validation Loss: 0.90, Validation Accuracy: 0.85\n",
            "Epoch: 41, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.53, Training Accuracy: 0.99, Validation Loss: 0.91, Validation Accuracy: 0.85\n",
            "Epoch: 42, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.53, Training Accuracy: 0.99, Validation Loss: 0.92, Validation Accuracy: 0.84\n",
            "Epoch: 43, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.52, Training Accuracy: 0.99, Validation Loss: 0.90, Validation Accuracy: 0.85\n",
            "Epoch: 44, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.53, Training Accuracy: 0.99, Validation Loss: 0.92, Validation Accuracy: 0.84\n",
            "Epoch: 45, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.52, Training Accuracy: 0.99, Validation Loss: 0.92, Validation Accuracy: 0.84\n",
            "Epoch: 46, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.53, Training Accuracy: 0.99, Validation Loss: 0.90, Validation Accuracy: 0.84\n",
            "Epoch: 47, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.52, Training Accuracy: 0.99, Validation Loss: 0.91, Validation Accuracy: 0.83\n",
            "Epoch: 48, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.52, Training Accuracy: 0.99, Validation Loss: 0.91, Validation Accuracy: 0.84\n",
            "Epoch: 49, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.54, Training Accuracy: 0.99, Validation Loss: 0.90, Validation Accuracy: 0.83\n",
            "Epoch: 50, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.53, Training Accuracy: 0.99, Validation Loss: 0.89, Validation Accuracy: 0.84\n",
            "Early stopping activated.\n",
            "\n",
            " Model has been saved to tensorboard_logs/2023-11-12_055831_ResNet50/best_model_ResNet50.pth\n",
            "\n",
            " Test Accuracy: 84.50%\n"
          ]
        }
      ],
      "source": [
        "import IPython.display as display\n",
        "\n",
        "import glob\n",
        "from collections import Counter\n",
        "\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import soundfile as sf\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import models, transforms\n",
        "import timm\n",
        "\n",
        "import tensorflow as tf\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import datetime\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "def evaluate(model, test_loader, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    num_correct = 0\n",
        "    num_examples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
        "            num_correct += torch.sum(correct).item()\n",
        "            num_examples += correct.shape[0]\n",
        "\n",
        "    accuracy = num_correct / num_examples\n",
        "    return accuracy\n",
        "\n",
        "class FrequencyMask(object):\n",
        "    \"\"\"\n",
        "      Example:\n",
        "        >>> transforms.Compose([\n",
        "        >>>     transforms.ToTensor(),\n",
        "        >>>     FrequencyMask(max_width=10, use_mean=False),\n",
        "        >>> ])\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, max_width, use_mean=True):\n",
        "        self.max_width = max_width\n",
        "        self.use_mean = use_mean\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tensor (Tensor): Tensor image of\n",
        "            size (C, H, W) where the frequency\n",
        "            mask is to be applied.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Transformed image with Frequency Mask.\n",
        "        \"\"\"\n",
        "        start = random.randrange(0, tensor.shape[2])\n",
        "        end = start + random.randrange(1, self.max_width)\n",
        "        if self.use_mean:\n",
        "            tensor[:, start:end, :] = tensor.mean()\n",
        "        else:\n",
        "            tensor[:, start:end, :] = 0\n",
        "        return tensor\n",
        "\n",
        "    def __repr__(self):\n",
        "        format_string = self.__class__.__name__ + \"(max_width=\"\n",
        "        format_string += str(self.max_width) + \")\"\n",
        "        format_string += 'use_mean=' + (str(self.use_mean) + ')')\n",
        "\n",
        "        return format_string\n",
        "\n",
        "\n",
        "class TimeMask(object):\n",
        "    \"\"\"\n",
        "      Example:\n",
        "        >>> transforms.Compose([\n",
        "        >>>     transforms.ToTensor(),\n",
        "        >>>     TimeMask(max_width=10, use_mean=False),\n",
        "        >>> ])\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, max_width, use_mean=True):\n",
        "        self.max_width = max_width\n",
        "        self.use_mean = use_mean\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tensor (Tensor): Tensor image of\n",
        "            size (C, H, W) where the time mask\n",
        "            is to be applied.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Transformed image with Time Mask.\n",
        "        \"\"\"\n",
        "        start = random.randrange(0, tensor.shape[1])\n",
        "        end = start + random.randrange(0, self.max_width)\n",
        "        if self.use_mean:\n",
        "            tensor[:, :, start:end] = tensor.mean()\n",
        "        else:\n",
        "            tensor[:, :, start:end] = 0\n",
        "        return tensor\n",
        "\n",
        "    def __repr__(self):\n",
        "        format_string = self.__class__.__name__ + \"(max_width=\"\n",
        "        format_string += str(self.max_width) + \")\"\n",
        "        format_string += 'use_mean=' + (str(self.use_mean) + ')')\n",
        "        return format_string\n",
        "\n",
        "\n",
        "class PrecomputedESC50(Dataset):\n",
        "    def __init__(self,path, max_freqmask_width, max_timemask_width, use_mean=True, dpi=50):\n",
        "        files = Path(path).glob('*.png')\n",
        "        self.items = [(f,int(f.name.split(\"-\")[-1].replace(\".wav.png\",\"\"))) for f in files]\n",
        "        self.length = len(self.items)\n",
        "        self.max_freqmask_width = max_freqmask_width\n",
        "        self.max_timemask_width = max_timemask_width\n",
        "        self.use_mean = use_mean\n",
        "        self.img_transforms = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
        "            transforms.RandomApply([FrequencyMask(self.max_freqmask_width, self.use_mean)], p=0.5),\n",
        "            transforms.RandomApply([TimeMask(self.max_timemask_width, self.use_mean)], p=0.5)])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename, label = self.items[index]\n",
        "        img = Image.open(filename).convert('RGB')\n",
        "        return (self.img_transforms(img), label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "# Define a function to plot and log confusion matrix to TensorBoard\n",
        "def plot_confusion_matrix(model, test_loader, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            predictions = torch.max(F.softmax(output, dim=1), dim=1)[1].cpu().numpy()\n",
        "            all_predictions.extend(predictions)\n",
        "            all_labels.extend(targets.cpu().numpy())\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "    # Create a heatmap of the confusion matrix\n",
        "    plt.figure(figsize=(20, 16))\n",
        "    sn.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=True, yticklabels=True)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "\n",
        "    figure = plt.gcf()\n",
        "    return figure\n",
        "\n",
        "# Define a function to log predictions vs. actuals as images to TensorBoard\n",
        "def log_predictions_vs_actuals(model, data_loader, device=\"cpu\", num_batches=5):\n",
        "    model.eval()\n",
        "\n",
        "    batch_counter = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            if batch_counter >= num_batches:\n",
        "                break\n",
        "\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            predictions = torch.max(F.softmax(output, dim=1), dim=1)\n",
        "            predicted_labels = predictions[1]\n",
        "            probabilities = predictions[0]\n",
        "\n",
        "            # Convert PyTorch tensors to NumPy arrays\n",
        "            inputs_np = inputs.permute(0, 2, 3, 1).cpu().numpy()\n",
        "\n",
        "            # Create a figure for each batch\n",
        "            fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(12, 12))\n",
        "\n",
        "            for i, ax in enumerate(axes.flat):\n",
        "                ax.imshow(inputs_np[i])\n",
        "                ax.axis(\"off\")\n",
        "\n",
        "                actual_label = targets[i].item()\n",
        "                predicted_label = predicted_labels[i].item()\n",
        "                probability = probabilities[i].item()\n",
        "\n",
        "                # Color the title based on correctness\n",
        "                title_color = 'green' if actual_label == predicted_label else 'red'\n",
        "\n",
        "                ax.set_title(f\"Actual: {actual_label}\\nPredicted: {predicted_label}\\nProb: {probability:.2f}\", color=title_color)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            batch_counter += 1\n",
        "    return fig\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience, verbose=False):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_valid_accuracy = 0.0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def step(self, valid_accuracy):\n",
        "        if valid_accuracy > self.best_valid_accuracy:\n",
        "            self.best_valid_accuracy = valid_accuracy\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter > self.patience:\n",
        "                self.early_stop = True\n",
        "                if self.verbose:\n",
        "                    print(\"Early stopping activated.\")\n",
        "        return self.early_stop\n",
        "\n",
        "class LearningRateScheduler(lr_scheduler._LRScheduler):\n",
        "    def __init__(self, optimizer, patience, factor=0.1, verbose=False):\n",
        "        self.optimizer = optimizer\n",
        "        self.patience = patience\n",
        "        self.factor = factor\n",
        "        self.verbose = verbose\n",
        "        self.lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=self.patience, factor=self.factor, verbose=self.verbose)\n",
        "\n",
        "    def step(self, valid_accuracy):\n",
        "        self.lr_scheduler.step(valid_accuracy)\n",
        "        return self.optimizer.param_groups[0]['lr']\n",
        "\n",
        "\n",
        "# Create a directory to store TensorBoard logs\n",
        "log_dir = 'tensorboard_logs'\n",
        "\n",
        "# Create a TensorBoard SummaryWriter\n",
        "load_model_name = \"ResNet50\"\n",
        "model_name = \"best_model_\" + load_model_name + \".pth\"\n",
        "\n",
        "current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
        "unique_folder_name = f\"{current_datetime}_{load_model_name}\"\n",
        "unique_log_dir = os.path.join(log_dir, unique_folder_name)\n",
        "\n",
        "layout = {\n",
        "    \"Train and validation at same time\": {\n",
        "        \"Loss\": [\"Multiline\", [\"Loss/Train\", \"Loss/Validation\"]],\n",
        "        \"Accuracy\": [\"Multiline\", [\"Accuracy/Train\", \"Accuracy/Validation\"]],\n",
        "    },\n",
        "}\n",
        "\n",
        "writer = SummaryWriter(log_dir=unique_log_dir)\n",
        "writer.add_custom_scalars(layout)\n",
        "\n",
        "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
        "    best_valid_accuracy = 0.0\n",
        "    best_model_state = None\n",
        "\n",
        "    # Save the model next to the log file\n",
        "    model_path = os.path.join(unique_log_dir, model_name)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        training_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        model.train()\n",
        "\n",
        "        # Initialize variables for train accuracy calculation\n",
        "        num_correct_train = 0\n",
        "        num_examples_train = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            loss = loss_fn(output, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            training_loss += loss.data.item() * inputs.size(0)\n",
        "\n",
        "            # Calculate the number of correct predictions in the current batch\n",
        "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
        "            num_correct_train += torch.sum(correct).item()\n",
        "            num_examples_train += correct.shape[0]\n",
        "\n",
        "        training_loss /= len(train_loader.dataset)\n",
        "        train_accuracy = num_correct_train / num_examples_train\n",
        "\n",
        "        model.eval()\n",
        "        num_correct = 0\n",
        "        num_examples = 0\n",
        "\n",
        "        for batch in val_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            output = model(inputs)\n",
        "            targets = targets.to(device)\n",
        "            loss = loss_fn(output, targets)\n",
        "            valid_loss += loss.data.item() * inputs.size(0)\n",
        "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
        "\n",
        "            num_correct += torch.sum(correct).item()\n",
        "            num_examples += correct.shape[0]\n",
        "\n",
        "        valid_loss /= len(val_loader.dataset)\n",
        "        valid_accuracy = num_correct / num_examples\n",
        "\n",
        "        # Get the current learning rate from the optimizer\n",
        "        current_lr = lr_scheduler.step(valid_accuracy)\n",
        "\n",
        "        print('Epoch: {}, Learning Rate: {}, Training Loss: {:.2f}, Training Accuracy: {:.2f}, Validation Loss: {:.2f}, Validation Accuracy: {:.2f}'.format(epoch, current_lr, training_loss, train_accuracy, valid_loss, valid_accuracy))\n",
        "\n",
        "        # Log training accuracy to TensorBoard\n",
        "        writer.add_scalar('Learning Rate', current_lr, epoch)\n",
        "        writer.add_scalar('Loss/Train', training_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/Train', train_accuracy, epoch)\n",
        "        writer.add_scalar('Loss/Validation', valid_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/Validation', valid_accuracy, epoch)\n",
        "\n",
        "        early_stop = early_stopping.step(valid_accuracy)\n",
        "        if early_stop:\n",
        "            break  # Stop training if early stopping is activated\n",
        "\n",
        "        # Save the best model based on validation accuracy\n",
        "        if valid_accuracy > best_valid_accuracy:\n",
        "            best_valid_accuracy = valid_accuracy\n",
        "            best_model_state = model.state_dict()\n",
        "            # Save the best model state to a file\n",
        "            torch.save(best_model_state, model_path)\n",
        "\n",
        "    print(f\"\\n Model has been saved to {model_path}\")\n",
        "\n",
        "    # Inspect the model\n",
        "    writer.add_graph(model, inputs)\n",
        "    writer.add_figure('Confusion Matrix', plot_confusion_matrix(model, val_loader, device))\n",
        "    # writer.add_figure(f\"Predictions vs. Actuals\", log_predictions_vs_actuals(model, val_loader, device=device, num_batches=1))\n",
        "\n",
        "    # Close the TensorBoard SummaryWriter\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "PATH_ESC50_TRAIN=\"./train1/\"\n",
        "PATH_ESC50_VALID=\"./valid1/\"\n",
        "PATH_ESC50_TEST=\"./test/\"\n",
        "\n",
        "bs=16\n",
        "esc50pre_train = PrecomputedESC50(PATH_ESC50_TRAIN, max_freqmask_width=10, max_timemask_width=10 )\n",
        "esc50pre_valid = PrecomputedESC50(PATH_ESC50_VALID,max_freqmask_width=10, max_timemask_width=10 )\n",
        "esc50pre_test = PrecomputedESC50(PATH_ESC50_TEST,max_freqmask_width=10, max_timemask_width=10 )\n",
        "\n",
        "esc50_train_loader = torch.utils.data.DataLoader(esc50pre_train, bs, shuffle=True)\n",
        "esc50_val_loader = torch.utils.data.DataLoader(esc50pre_valid, bs, shuffle=True)\n",
        "esc50_test_loader = torch.utils.data.DataLoader(esc50pre_test, bs, shuffle=True)\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Replace the last fully connected layer\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_features, 500),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(),\n",
        "    nn.Linear(500, 50)\n",
        ")\n",
        "\n",
        "lr = 1e-2\n",
        "model.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "                        {'params': model.conv1.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.layer1.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.layer2.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.layer3.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.layer4.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.fc.parameters(), 'lr': 1e-8}\n",
        "                        ], lr=1e-2)\n",
        "\n",
        "# Use these classes during training\n",
        "patience = 5\n",
        "early_stopping_patience=2*patience\n",
        "early_stopping = EarlyStopping(patience=early_stopping_patience, verbose=True)\n",
        "lr_scheduler = LearningRateScheduler(optimizer, patience=patience, factor=0.1, verbose=True)\n",
        "\n",
        "train(model, optimizer, nn.CrossEntropyLoss(), esc50_train_loader, esc50_val_loader, epochs=50, device=device)\n",
        "\n",
        "test_accuracy = evaluate(model, esc50_test_loader, device=device)\n",
        "print(f\"\\n Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TAD29LLmFQV6"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "069e6224-2642-4ee4-abee-93bf6bda9c5e",
        "id": "K4KYIhh_FQV6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-10_120231_tf_efficientnetv2_b3\t2023-11-10_123852_tf_efficientnetv2_b3\n",
            "2023-11-10_123147_tf_efficientnetv2_b3\t2023-11-11_051023_tf_efficientnetv2_b3\n"
          ]
        }
      ],
      "source": [
        "!ls tensorboard_logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JspYdlKvFQV7"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir tensorboard_logs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet152"
      ],
      "metadata": {
        "id": "A6ldoxPBLFgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory to store TensorBoard logs\n",
        "log_dir = 'tensorboard_logs'\n",
        "\n",
        "# Create a TensorBoard SummaryWriter\n",
        "load_model_name = \"ResNet152\"\n",
        "model_name = \"best_model_\" + load_model_name + \".pth\"\n",
        "\n",
        "current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
        "unique_folder_name = f\"{current_datetime}_{load_model_name}\"\n",
        "unique_log_dir = os.path.join(log_dir, unique_folder_name)\n",
        "\n",
        "layout = {\n",
        "    \"Train and validation at same time\": {\n",
        "        \"Loss\": [\"Multiline\", [\"Loss/Train\", \"Loss/Validation\"]],\n",
        "        \"Accuracy\": [\"Multiline\", [\"Accuracy/Train\", \"Accuracy/Validation\"]],\n",
        "    },\n",
        "}\n",
        "\n",
        "writer = SummaryWriter(log_dir=unique_log_dir)\n",
        "writer.add_custom_scalars(layout)\n",
        "\n",
        "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
        "    best_valid_accuracy = 0.0\n",
        "    best_model_state = None\n",
        "\n",
        "    # Save the model next to the log file\n",
        "    model_path = os.path.join(unique_log_dir, model_name)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        training_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        model.train()\n",
        "\n",
        "        # Initialize variables for train accuracy calculation\n",
        "        num_correct_train = 0\n",
        "        num_examples_train = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            loss = loss_fn(output, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            training_loss += loss.data.item() * inputs.size(0)\n",
        "\n",
        "            # Calculate the number of correct predictions in the current batch\n",
        "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
        "            num_correct_train += torch.sum(correct).item()\n",
        "            num_examples_train += correct.shape[0]\n",
        "\n",
        "        training_loss /= len(train_loader.dataset)\n",
        "        train_accuracy = num_correct_train / num_examples_train\n",
        "\n",
        "        model.eval()\n",
        "        num_correct = 0\n",
        "        num_examples = 0\n",
        "\n",
        "        for batch in val_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            output = model(inputs)\n",
        "            targets = targets.to(device)\n",
        "            loss = loss_fn(output, targets)\n",
        "            valid_loss += loss.data.item() * inputs.size(0)\n",
        "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
        "\n",
        "            num_correct += torch.sum(correct).item()\n",
        "            num_examples += correct.shape[0]\n",
        "\n",
        "        valid_loss /= len(val_loader.dataset)\n",
        "        valid_accuracy = num_correct / num_examples\n",
        "\n",
        "        # Get the current learning rate from the optimizer\n",
        "        current_lr = lr_scheduler.step(valid_accuracy)\n",
        "\n",
        "        print('Epoch: {}, Learning Rate: {}, Training Loss: {:.2f}, Training Accuracy: {:.2f}, Validation Loss: {:.2f}, Validation Accuracy: {:.2f}'.format(epoch, current_lr, training_loss, train_accuracy, valid_loss, valid_accuracy))\n",
        "\n",
        "        # Log training accuracy to TensorBoard\n",
        "        writer.add_scalar('Learning Rate', current_lr, epoch)\n",
        "        writer.add_scalar('Loss/Train', training_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/Train', train_accuracy, epoch)\n",
        "        writer.add_scalar('Loss/Validation', valid_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/Validation', valid_accuracy, epoch)\n",
        "\n",
        "        early_stop = early_stopping.step(valid_accuracy)\n",
        "        if early_stop:\n",
        "            break  # Stop training if early stopping is activated\n",
        "\n",
        "        # Save the best model based on validation accuracy\n",
        "        if valid_accuracy > best_valid_accuracy:\n",
        "            best_valid_accuracy = valid_accuracy\n",
        "            best_model_state = model.state_dict()\n",
        "            # Save the best model state to a file\n",
        "            torch.save(best_model_state, model_path)\n",
        "\n",
        "    print(f\"\\n Model has been saved to {model_path}\")\n",
        "\n",
        "    # Inspect the model\n",
        "    writer.add_graph(model, inputs)\n",
        "    writer.add_figure('Confusion Matrix', plot_confusion_matrix(model, val_loader, device))\n",
        "    # writer.add_figure(f\"Predictions vs. Actuals\", log_predictions_vs_actuals(model, val_loader, device=device, num_batches=1))\n",
        "\n",
        "    # Close the TensorBoard SummaryWriter\n",
        "    writer.close()\n",
        "\n",
        "model = models.resnet152(pretrained=True)\n",
        "\n",
        "# Replace the last fully connected layer\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_features, 500),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(),\n",
        "    nn.Linear(500, 50)\n",
        ")\n",
        "\n",
        "lr = 1e-2\n",
        "model.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "                        {'params': model.conv1.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.layer1.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.layer2.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.layer3.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.layer4.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.fc.parameters(), 'lr': 1e-8}\n",
        "                        ], lr=1e-2)\n",
        "\n",
        "# Use these classes during training\n",
        "patience = 5\n",
        "early_stopping_patience=8\n",
        "early_stopping = EarlyStopping(patience=early_stopping_patience, verbose=True)\n",
        "lr_scheduler = LearningRateScheduler(optimizer, patience=patience, factor=0.1, verbose=True)\n",
        "\n",
        "train(model, optimizer, nn.CrossEntropyLoss(), esc50_train_loader, esc50_val_loader, epochs=50, device=device)\n",
        "\n",
        "test_accuracy = evaluate(model, esc50_test_loader, device=device)\n",
        "print(f\"\\n Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xIRKDc4LGRm",
        "outputId": "bb123077-888f-43c1-a653-dbbf4cb242d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Learning Rate: 0.0001, Training Loss: 3.58, Training Accuracy: 0.20, Validation Loss: 3.08, Validation Accuracy: 0.43\n",
            "Epoch: 2, Learning Rate: 0.0001, Training Loss: 2.84, Training Accuracy: 0.43, Validation Loss: 2.33, Validation Accuracy: 0.54\n",
            "Epoch: 3, Learning Rate: 0.0001, Training Loss: 2.28, Training Accuracy: 0.60, Validation Loss: 2.03, Validation Accuracy: 0.58\n",
            "Epoch: 4, Learning Rate: 0.0001, Training Loss: 1.80, Training Accuracy: 0.70, Validation Loss: 1.50, Validation Accuracy: 0.71\n",
            "Epoch: 5, Learning Rate: 0.0001, Training Loss: 1.35, Training Accuracy: 0.82, Validation Loss: 1.51, Validation Accuracy: 0.68\n",
            "Epoch: 6, Learning Rate: 0.0001, Training Loss: 1.14, Training Accuracy: 0.85, Validation Loss: 1.19, Validation Accuracy: 0.75\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch 00007: reducing learning rate of group 1 to 1.0000e-05.\n",
            "Epoch 00007: reducing learning rate of group 2 to 1.0000e-05.\n",
            "Epoch 00007: reducing learning rate of group 3 to 1.0000e-05.\n",
            "Epoch 00007: reducing learning rate of group 4 to 1.0000e-05.\n",
            "Epoch: 7, Learning Rate: 1e-05, Training Loss: 0.84, Training Accuracy: 0.91, Validation Loss: 1.13, Validation Accuracy: 0.76\n",
            "Epoch: 8, Learning Rate: 1e-05, Training Loss: 0.61, Training Accuracy: 0.94, Validation Loss: 0.79, Validation Accuracy: 0.85\n",
            "Epoch: 9, Learning Rate: 1e-05, Training Loss: 0.49, Training Accuracy: 0.98, Validation Loss: 0.75, Validation Accuracy: 0.87\n",
            "Epoch: 10, Learning Rate: 1e-05, Training Loss: 0.46, Training Accuracy: 0.98, Validation Loss: 0.76, Validation Accuracy: 0.86\n",
            "Epoch: 11, Learning Rate: 1e-05, Training Loss: 0.42, Training Accuracy: 0.98, Validation Loss: 0.75, Validation Accuracy: 0.85\n",
            "Epoch: 12, Learning Rate: 1e-05, Training Loss: 0.40, Training Accuracy: 0.99, Validation Loss: 0.70, Validation Accuracy: 0.88\n",
            "Epoch 00013: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch 00013: reducing learning rate of group 1 to 1.0000e-06.\n",
            "Epoch 00013: reducing learning rate of group 2 to 1.0000e-06.\n",
            "Epoch 00013: reducing learning rate of group 3 to 1.0000e-06.\n",
            "Epoch 00013: reducing learning rate of group 4 to 1.0000e-06.\n",
            "Epoch: 13, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.36, Training Accuracy: 0.99, Validation Loss: 0.68, Validation Accuracy: 0.86\n",
            "Epoch: 14, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.35, Training Accuracy: 0.99, Validation Loss: 0.69, Validation Accuracy: 0.85\n",
            "Epoch: 15, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.35, Training Accuracy: 0.99, Validation Loss: 0.68, Validation Accuracy: 0.86\n",
            "Epoch: 16, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.34, Training Accuracy: 0.99, Validation Loss: 0.68, Validation Accuracy: 0.87\n",
            "Epoch: 17, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.34, Training Accuracy: 0.99, Validation Loss: 0.65, Validation Accuracy: 0.87\n",
            "Epoch: 18, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.32, Training Accuracy: 0.99, Validation Loss: 0.65, Validation Accuracy: 0.87\n",
            "Epoch 00019: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Epoch 00019: reducing learning rate of group 1 to 1.0000e-07.\n",
            "Epoch 00019: reducing learning rate of group 2 to 1.0000e-07.\n",
            "Epoch 00019: reducing learning rate of group 3 to 1.0000e-07.\n",
            "Epoch 00019: reducing learning rate of group 4 to 1.0000e-07.\n",
            "Epoch: 19, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.33, Training Accuracy: 0.99, Validation Loss: 0.65, Validation Accuracy: 0.88\n",
            "Epoch: 20, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.34, Training Accuracy: 0.99, Validation Loss: 0.66, Validation Accuracy: 0.88\n",
            "Epoch: 21, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.34, Training Accuracy: 0.99, Validation Loss: 0.64, Validation Accuracy: 0.86\n",
            "Early stopping activated.\n",
            "\n",
            " Model has been saved to tensorboard_logs/2023-11-12_063546_ResNet152/best_model_ResNet152.pth\n",
            "\n",
            " Test Accuracy: 85.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### wide Resnet 101-2"
      ],
      "metadata": {
        "id": "YEu6CSlHT-mq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "bring `model_path` out of train function to use saved model on test data"
      ],
      "metadata": {
        "id": "KghPEd_-Ue7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory to store TensorBoard logs\n",
        "log_dir = 'tensorboard_logs'\n",
        "\n",
        "# Create a TensorBoard SummaryWriter\n",
        "load_model_name = \"wide_resnet101_2\"\n",
        "model_name = \"best_model_\" + load_model_name + \".pth\"\n",
        "\n",
        "current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
        "unique_folder_name = f\"{current_datetime}_{load_model_name}\"\n",
        "unique_log_dir = os.path.join(log_dir, unique_folder_name)\n",
        "model_path = os.path.join(unique_log_dir, model_name)\n",
        "\n",
        "layout = {\n",
        "    \"Train and validation at same time\": {\n",
        "        \"Loss\": [\"Multiline\", [\"Loss/Train\", \"Loss/Validation\"]],\n",
        "        \"Accuracy\": [\"Multiline\", [\"Accuracy/Train\", \"Accuracy/Validation\"]],\n",
        "    },\n",
        "}\n",
        "\n",
        "writer = SummaryWriter(log_dir=unique_log_dir)\n",
        "writer.add_custom_scalars(layout)\n",
        "\n",
        "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
        "    best_valid_accuracy = 0.0\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        training_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        model.train()\n",
        "\n",
        "        # Initialize variables for train accuracy calculation\n",
        "        num_correct_train = 0\n",
        "        num_examples_train = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            loss = loss_fn(output, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            training_loss += loss.data.item() * inputs.size(0)\n",
        "\n",
        "            # Calculate the number of correct predictions in the current batch\n",
        "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
        "            num_correct_train += torch.sum(correct).item()\n",
        "            num_examples_train += correct.shape[0]\n",
        "\n",
        "        training_loss /= len(train_loader.dataset)\n",
        "        train_accuracy = num_correct_train / num_examples_train\n",
        "\n",
        "        model.eval()\n",
        "        num_correct = 0\n",
        "        num_examples = 0\n",
        "\n",
        "        for batch in val_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            output = model(inputs)\n",
        "            targets = targets.to(device)\n",
        "            loss = loss_fn(output, targets)\n",
        "            valid_loss += loss.data.item() * inputs.size(0)\n",
        "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
        "\n",
        "            num_correct += torch.sum(correct).item()\n",
        "            num_examples += correct.shape[0]\n",
        "\n",
        "        valid_loss /= len(val_loader.dataset)\n",
        "        valid_accuracy = num_correct / num_examples\n",
        "\n",
        "        # Get the current learning rate from the optimizer\n",
        "        current_lr = lr_scheduler.step(valid_accuracy)\n",
        "\n",
        "        print('Epoch: {}, Learning Rate: {}, Training Loss: {:.2f}, Training Accuracy: {:.2f}, Validation Loss: {:.2f}, Validation Accuracy: {:.2f}'.format(epoch, current_lr, training_loss, train_accuracy, valid_loss, valid_accuracy))\n",
        "\n",
        "        # Log training accuracy to TensorBoard\n",
        "        writer.add_scalar('Learning Rate', current_lr, epoch)\n",
        "        writer.add_scalar('Loss/Train', training_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/Train', train_accuracy, epoch)\n",
        "        writer.add_scalar('Loss/Validation', valid_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/Validation', valid_accuracy, epoch)\n",
        "\n",
        "        early_stop = early_stopping.step(valid_accuracy)\n",
        "        if early_stop:\n",
        "            break  # Stop training if early stopping is activated\n",
        "\n",
        "        # Save the best model based on validation accuracy\n",
        "        if valid_accuracy > best_valid_accuracy:\n",
        "            best_valid_accuracy = valid_accuracy\n",
        "            best_model_state = model.state_dict()\n",
        "            # Save the best model state to a file\n",
        "            torch.save(best_model_state, model_path)\n",
        "\n",
        "    print(f\"\\n Model has been saved to {model_path}\")\n",
        "\n",
        "    # Inspect the model\n",
        "    writer.add_graph(model, inputs)\n",
        "    writer.add_figure('Confusion Matrix', plot_confusion_matrix(model, val_loader, device))\n",
        "    # writer.add_figure(f\"Predictions vs. Actuals\", log_predictions_vs_actuals(model, val_loader, device=device, num_batches=1))\n",
        "\n",
        "    # Close the TensorBoard SummaryWriter\n",
        "    writer.close()\n",
        "\n",
        "model = models.wide_resnet101_2(pretrained=True)\n",
        "\n",
        "# Replace the last fully connected layer\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_features, 500),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(),\n",
        "    nn.Linear(500, 50)\n",
        ")\n",
        "\n",
        "lr = 1e-2\n",
        "model.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "                        {'params': model.conv1.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.layer1.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.layer2.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.layer3.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.layer4.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.fc.parameters(), 'lr': 1e-8}\n",
        "                        ], lr=1e-2)\n",
        "\n",
        "# Use these classes during training\n",
        "patience = 5\n",
        "early_stopping_patience=10\n",
        "early_stopping = EarlyStopping(patience=early_stopping_patience, verbose=True)\n",
        "lr_scheduler = LearningRateScheduler(optimizer, patience=patience, factor=0.1, verbose=True)\n",
        "\n",
        "train(model, optimizer, nn.CrossEntropyLoss(), esc50_train_loader, esc50_val_loader, epochs=50, device=device)\n",
        "\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "test_accuracy = evaluate(model, esc50_test_loader, device=device)\n",
        "print(f\"\\n Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d0e4df-0ff6-48d3-9c20-6f374a302032",
        "id": "wHZLQRP8T-nm"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet101_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet101_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth\" to /root/.cache/torch/hub/checkpoints/wide_resnet101_2-32ee1156.pth\n",
            "100%|██████████| 243M/243M [00:08<00:00, 31.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Learning Rate: 0.0001, Training Loss: 3.62, Training Accuracy: 0.20, Validation Loss: 3.54, Validation Accuracy: 0.30\n",
            "Epoch: 2, Learning Rate: 0.0001, Training Loss: 2.98, Training Accuracy: 0.50, Validation Loss: 2.54, Validation Accuracy: 0.50\n",
            "Epoch: 3, Learning Rate: 0.0001, Training Loss: 2.50, Training Accuracy: 0.64, Validation Loss: 1.97, Validation Accuracy: 0.50\n",
            "Epoch: 4, Learning Rate: 0.0001, Training Loss: 2.04, Training Accuracy: 0.79, Validation Loss: 2.28, Validation Accuracy: 0.50\n",
            "Epoch: 5, Learning Rate: 0.0001, Training Loss: 1.64, Training Accuracy: 0.85, Validation Loss: 2.09, Validation Accuracy: 0.60\n",
            "Epoch: 6, Learning Rate: 0.0001, Training Loss: 1.42, Training Accuracy: 0.90, Validation Loss: 1.97, Validation Accuracy: 0.70\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch 00007: reducing learning rate of group 1 to 1.0000e-05.\n",
            "Epoch 00007: reducing learning rate of group 2 to 1.0000e-05.\n",
            "Epoch 00007: reducing learning rate of group 3 to 1.0000e-05.\n",
            "Epoch 00007: reducing learning rate of group 4 to 1.0000e-05.\n",
            "Epoch: 7, Learning Rate: 1e-05, Training Loss: 1.18, Training Accuracy: 0.94, Validation Loss: 1.36, Validation Accuracy: 0.90\n",
            "Epoch: 8, Learning Rate: 1e-05, Training Loss: 0.94, Training Accuracy: 0.98, Validation Loss: 1.62, Validation Accuracy: 0.70\n",
            "Epoch: 9, Learning Rate: 1e-05, Training Loss: 0.85, Training Accuracy: 0.99, Validation Loss: 1.46, Validation Accuracy: 0.90\n",
            "Epoch: 10, Learning Rate: 1e-05, Training Loss: 0.82, Training Accuracy: 0.99, Validation Loss: 1.05, Validation Accuracy: 0.90\n",
            "Epoch: 11, Learning Rate: 1e-05, Training Loss: 0.78, Training Accuracy: 1.00, Validation Loss: 1.13, Validation Accuracy: 0.90\n",
            "Epoch: 12, Learning Rate: 1e-05, Training Loss: 0.75, Training Accuracy: 1.00, Validation Loss: 1.39, Validation Accuracy: 0.90\n",
            "Epoch 00013: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch 00013: reducing learning rate of group 1 to 1.0000e-06.\n",
            "Epoch 00013: reducing learning rate of group 2 to 1.0000e-06.\n",
            "Epoch 00013: reducing learning rate of group 3 to 1.0000e-06.\n",
            "Epoch 00013: reducing learning rate of group 4 to 1.0000e-06.\n",
            "Epoch: 13, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.75, Training Accuracy: 1.00, Validation Loss: 1.16, Validation Accuracy: 0.90\n",
            "Epoch: 14, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.72, Training Accuracy: 1.00, Validation Loss: 1.37, Validation Accuracy: 1.00\n",
            "Epoch: 15, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.72, Training Accuracy: 1.00, Validation Loss: 1.13, Validation Accuracy: 1.00\n",
            "Epoch: 16, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.73, Training Accuracy: 1.00, Validation Loss: 0.94, Validation Accuracy: 1.00\n",
            "Epoch: 17, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.71, Training Accuracy: 1.00, Validation Loss: 1.20, Validation Accuracy: 0.90\n",
            "Epoch: 18, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.71, Training Accuracy: 1.00, Validation Loss: 1.17, Validation Accuracy: 0.90\n",
            "Epoch 00019: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Epoch 00019: reducing learning rate of group 1 to 1.0000e-07.\n",
            "Epoch 00019: reducing learning rate of group 2 to 1.0000e-07.\n",
            "Epoch 00019: reducing learning rate of group 3 to 1.0000e-07.\n",
            "Epoch 00019: reducing learning rate of group 4 to 1.0000e-07.\n",
            "Epoch: 19, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.71, Training Accuracy: 1.00, Validation Loss: 1.18, Validation Accuracy: 0.90\n",
            "Epoch: 20, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.70, Training Accuracy: 1.00, Validation Loss: 1.32, Validation Accuracy: 0.90\n",
            "Epoch: 21, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.70, Training Accuracy: 1.00, Validation Loss: 1.26, Validation Accuracy: 0.90\n",
            "Epoch: 22, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.70, Training Accuracy: 1.00, Validation Loss: 1.44, Validation Accuracy: 0.90\n",
            "Epoch: 23, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.71, Training Accuracy: 0.99, Validation Loss: 1.12, Validation Accuracy: 1.00\n",
            "Epoch: 24, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.72, Training Accuracy: 1.00, Validation Loss: 1.21, Validation Accuracy: 0.90\n",
            "Epoch 00025: reducing learning rate of group 0 to 1.0000e-08.\n",
            "Epoch 00025: reducing learning rate of group 1 to 1.0000e-08.\n",
            "Epoch 00025: reducing learning rate of group 2 to 1.0000e-08.\n",
            "Epoch 00025: reducing learning rate of group 3 to 1.0000e-08.\n",
            "Epoch 00025: reducing learning rate of group 4 to 1.0000e-08.\n",
            "Epoch: 25, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.71, Training Accuracy: 1.00, Validation Loss: 1.06, Validation Accuracy: 1.00\n",
            "Early stopping activated.\n",
            "\n",
            " Model has been saved to tensorboard_logs/2023-11-12_121905_wide_resnet101_2/best_model_wide_resnet101_2.pth\n",
            "\n",
            " Test Accuracy: 88.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNeXt-101"
      ],
      "metadata": {
        "id": "b7NYWzi_ph9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory to store TensorBoard logs\n",
        "log_dir = 'tensorboard_logs'\n",
        "\n",
        "# Create a TensorBoard SummaryWriter\n",
        "load_model_name = \"resnext101_32x8d\"\n",
        "model_name = \"best_model_\" + load_model_name + \".pth\"\n",
        "\n",
        "current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
        "unique_folder_name = f\"{current_datetime}_{load_model_name}\"\n",
        "unique_log_dir = os.path.join(log_dir, unique_folder_name)\n",
        "model_path = os.path.join(unique_log_dir, model_name)\n",
        "\n",
        "layout = {\n",
        "    \"Train and validation at same time\": {\n",
        "        \"Loss\": [\"Multiline\", [\"Loss/Train\", \"Loss/Validation\"]],\n",
        "        \"Accuracy\": [\"Multiline\", [\"Accuracy/Train\", \"Accuracy/Validation\"]],\n",
        "    },\n",
        "}\n",
        "\n",
        "writer = SummaryWriter(log_dir=unique_log_dir)\n",
        "writer.add_custom_scalars(layout)\n",
        "\n",
        "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
        "    best_valid_accuracy = 0.0\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        training_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        model.train()\n",
        "\n",
        "        # Initialize variables for train accuracy calculation\n",
        "        num_correct_train = 0\n",
        "        num_examples_train = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            loss = loss_fn(output, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            training_loss += loss.data.item() * inputs.size(0)\n",
        "\n",
        "            # Calculate the number of correct predictions in the current batch\n",
        "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
        "            num_correct_train += torch.sum(correct).item()\n",
        "            num_examples_train += correct.shape[0]\n",
        "\n",
        "        training_loss /= len(train_loader.dataset)\n",
        "        train_accuracy = num_correct_train / num_examples_train\n",
        "\n",
        "        model.eval()\n",
        "        num_correct = 0\n",
        "        num_examples = 0\n",
        "\n",
        "        for batch in val_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            output = model(inputs)\n",
        "            targets = targets.to(device)\n",
        "            loss = loss_fn(output, targets)\n",
        "            valid_loss += loss.data.item() * inputs.size(0)\n",
        "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
        "\n",
        "            num_correct += torch.sum(correct).item()\n",
        "            num_examples += correct.shape[0]\n",
        "\n",
        "        valid_loss /= len(val_loader.dataset)\n",
        "        valid_accuracy = num_correct / num_examples\n",
        "\n",
        "        # Get the current learning rate from the optimizer\n",
        "        current_lr = lr_scheduler.step(valid_accuracy)\n",
        "\n",
        "        print('Epoch: {}, Learning Rate: {}, Training Loss: {:.2f}, Training Accuracy: {:.2f}, Validation Loss: {:.2f}, Validation Accuracy: {:.2f}'.format(epoch, current_lr, training_loss, train_accuracy, valid_loss, valid_accuracy))\n",
        "\n",
        "        # Log training accuracy to TensorBoard\n",
        "        writer.add_scalar('Learning Rate', current_lr, epoch)\n",
        "        writer.add_scalar('Loss/Train', training_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/Train', train_accuracy, epoch)\n",
        "        writer.add_scalar('Loss/Validation', valid_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/Validation', valid_accuracy, epoch)\n",
        "\n",
        "        early_stop = early_stopping.step(valid_accuracy)\n",
        "        if early_stop:\n",
        "            break  # Stop training if early stopping is activated\n",
        "\n",
        "        # Save the best model based on validation accuracy\n",
        "        if valid_accuracy > best_valid_accuracy:\n",
        "            best_valid_accuracy = valid_accuracy\n",
        "            best_model_state = model.state_dict()\n",
        "            # Save the best model state to a file\n",
        "            torch.save(best_model_state, model_path)\n",
        "\n",
        "    print(f\"\\n Model has been saved to {model_path}\")\n",
        "\n",
        "    # Inspect the model\n",
        "    writer.add_graph(model, inputs)\n",
        "    writer.add_figure('Confusion Matrix', plot_confusion_matrix(model, val_loader, device))\n",
        "    # writer.add_figure(f\"Predictions vs. Actuals\", log_predictions_vs_actuals(model, val_loader, device=device, num_batches=1))\n",
        "\n",
        "    # Close the TensorBoard SummaryWriter\n",
        "    writer.close()\n",
        "\n",
        "model = models.resnext101_32x8d(pretrained=True)\n",
        "\n",
        "# Replace the last fully connected layer\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_features, 500),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(),\n",
        "    nn.Linear(500, 50)\n",
        ")\n",
        "\n",
        "lr = 1e-2\n",
        "model.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "                        {'params': model.conv1.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.layer1.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.layer2.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.layer3.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.layer4.parameters(), 'lr': 1e-4},\n",
        "                        {'params': model.fc.parameters(), 'lr': 1e-8}\n",
        "                        ], lr=1e-2)\n",
        "\n",
        "# Use these classes during training\n",
        "patience = 5\n",
        "early_stopping_patience=10\n",
        "early_stopping = EarlyStopping(patience=early_stopping_patience, verbose=True)\n",
        "lr_scheduler = LearningRateScheduler(optimizer, patience=patience, factor=0.1, verbose=True)\n",
        "\n",
        "train(model, optimizer, nn.CrossEntropyLoss(), esc50_train_loader, esc50_val_loader, epochs=50, device=device)\n",
        "\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "test_accuracy = evaluate(model, esc50_test_loader, device=device)\n",
        "print(f\"\\n Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da54eb8b-0352-469f-80fe-1e18c2c0158f",
        "id": "p-UAun5Uph9h"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt101_32X8D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt101_32X8D_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth\" to /root/.cache/torch/hub/checkpoints/resnext101_32x8d-8ba56ff5.pth\n",
            "100%|██████████| 340M/340M [00:04<00:00, 72.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Learning Rate: 0.0001, Training Loss: 3.37, Training Accuracy: 0.26, Validation Loss: 2.56, Validation Accuracy: 0.52\n",
            "Epoch: 2, Learning Rate: 0.0001, Training Loss: 2.37, Training Accuracy: 0.61, Validation Loss: 1.88, Validation Accuracy: 0.61\n",
            "Epoch: 3, Learning Rate: 0.0001, Training Loss: 1.71, Training Accuracy: 0.76, Validation Loss: 1.39, Validation Accuracy: 0.73\n",
            "Epoch: 4, Learning Rate: 0.0001, Training Loss: 1.20, Training Accuracy: 0.87, Validation Loss: 1.34, Validation Accuracy: 0.72\n",
            "Epoch: 5, Learning Rate: 0.0001, Training Loss: 0.95, Training Accuracy: 0.91, Validation Loss: 1.23, Validation Accuracy: 0.76\n",
            "Epoch: 6, Learning Rate: 0.0001, Training Loss: 0.73, Training Accuracy: 0.93, Validation Loss: 1.19, Validation Accuracy: 0.73\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch 00007: reducing learning rate of group 1 to 1.0000e-05.\n",
            "Epoch 00007: reducing learning rate of group 2 to 1.0000e-05.\n",
            "Epoch 00007: reducing learning rate of group 3 to 1.0000e-05.\n",
            "Epoch 00007: reducing learning rate of group 4 to 1.0000e-05.\n",
            "Epoch: 7, Learning Rate: 1e-05, Training Loss: 0.59, Training Accuracy: 0.95, Validation Loss: 0.94, Validation Accuracy: 0.82\n",
            "Epoch: 8, Learning Rate: 1e-05, Training Loss: 0.42, Training Accuracy: 0.98, Validation Loss: 0.68, Validation Accuracy: 0.88\n",
            "Epoch: 9, Learning Rate: 1e-05, Training Loss: 0.35, Training Accuracy: 0.99, Validation Loss: 0.71, Validation Accuracy: 0.87\n",
            "Epoch: 10, Learning Rate: 1e-05, Training Loss: 0.32, Training Accuracy: 1.00, Validation Loss: 0.63, Validation Accuracy: 0.89\n",
            "Epoch: 11, Learning Rate: 1e-05, Training Loss: 0.28, Training Accuracy: 1.00, Validation Loss: 0.63, Validation Accuracy: 0.88\n",
            "Epoch: 12, Learning Rate: 1e-05, Training Loss: 0.27, Training Accuracy: 1.00, Validation Loss: 0.63, Validation Accuracy: 0.88\n",
            "Epoch 00013: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch 00013: reducing learning rate of group 1 to 1.0000e-06.\n",
            "Epoch 00013: reducing learning rate of group 2 to 1.0000e-06.\n",
            "Epoch 00013: reducing learning rate of group 3 to 1.0000e-06.\n",
            "Epoch 00013: reducing learning rate of group 4 to 1.0000e-06.\n",
            "Epoch: 13, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.26, Training Accuracy: 1.00, Validation Loss: 0.61, Validation Accuracy: 0.88\n",
            "Epoch: 14, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.26, Training Accuracy: 1.00, Validation Loss: 0.59, Validation Accuracy: 0.88\n",
            "Epoch: 15, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.25, Training Accuracy: 1.00, Validation Loss: 0.61, Validation Accuracy: 0.88\n",
            "Epoch: 16, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.24, Training Accuracy: 1.00, Validation Loss: 0.62, Validation Accuracy: 0.87\n",
            "Epoch: 17, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.24, Training Accuracy: 1.00, Validation Loss: 0.61, Validation Accuracy: 0.90\n",
            "Epoch: 18, Learning Rate: 1.0000000000000002e-06, Training Loss: 0.25, Training Accuracy: 1.00, Validation Loss: 0.59, Validation Accuracy: 0.88\n",
            "Epoch 00019: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Epoch 00019: reducing learning rate of group 1 to 1.0000e-07.\n",
            "Epoch 00019: reducing learning rate of group 2 to 1.0000e-07.\n",
            "Epoch 00019: reducing learning rate of group 3 to 1.0000e-07.\n",
            "Epoch 00019: reducing learning rate of group 4 to 1.0000e-07.\n",
            "Epoch: 19, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.24, Training Accuracy: 1.00, Validation Loss: 0.61, Validation Accuracy: 0.88\n",
            "Epoch: 20, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.23, Training Accuracy: 1.00, Validation Loss: 0.59, Validation Accuracy: 0.88\n",
            "Epoch: 21, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.24, Training Accuracy: 1.00, Validation Loss: 0.62, Validation Accuracy: 0.87\n",
            "Epoch: 22, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.24, Training Accuracy: 1.00, Validation Loss: 0.59, Validation Accuracy: 0.88\n",
            "Epoch: 23, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.25, Training Accuracy: 1.00, Validation Loss: 0.60, Validation Accuracy: 0.89\n",
            "Epoch: 24, Learning Rate: 1.0000000000000002e-07, Training Loss: 0.24, Training Accuracy: 1.00, Validation Loss: 0.60, Validation Accuracy: 0.88\n",
            "Epoch 00025: reducing learning rate of group 0 to 1.0000e-08.\n",
            "Epoch 00025: reducing learning rate of group 1 to 1.0000e-08.\n",
            "Epoch 00025: reducing learning rate of group 2 to 1.0000e-08.\n",
            "Epoch 00025: reducing learning rate of group 3 to 1.0000e-08.\n",
            "Epoch 00025: reducing learning rate of group 4 to 1.0000e-08.\n",
            "Epoch: 25, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.24, Training Accuracy: 1.00, Validation Loss: 0.58, Validation Accuracy: 0.89\n",
            "Epoch: 26, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.23, Training Accuracy: 1.00, Validation Loss: 0.60, Validation Accuracy: 0.89\n",
            "Epoch: 27, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.23, Training Accuracy: 1.00, Validation Loss: 0.58, Validation Accuracy: 0.88\n",
            "Epoch: 28, Learning Rate: 1.0000000000000004e-08, Training Loss: 0.24, Training Accuracy: 1.00, Validation Loss: 0.57, Validation Accuracy: 0.89\n",
            "Early stopping activated.\n",
            "\n",
            " Model has been saved to tensorboard_logs/2023-11-13_075020_resnext101_32x8d/best_model_resnext101_32x8d.pth\n",
            "\n",
            " Test Accuracy: 88.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MobileNet V3 Large"
      ],
      "metadata": {
        "id": "3DpDBM_t08Wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory to store TensorBoard logs\n",
        "log_dir = 'tensorboard_logs'\n",
        "\n",
        "# Create a TensorBoard SummaryWriter\n",
        "load_model_name = \"mobilenet_v3_large_without_lr_scheduler\"\n",
        "model_name = \"best_model_\" + load_model_name + \".pth\"\n",
        "\n",
        "current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
        "unique_folder_name = f\"{current_datetime}_{load_model_name}\"\n",
        "unique_log_dir = os.path.join(log_dir, unique_folder_name)\n",
        "model_path = os.path.join(unique_log_dir, model_name)\n",
        "\n",
        "layout = {\n",
        "    \"Train and validation at same time\": {\n",
        "        \"Loss\": [\"Multiline\", [\"Loss/Train\", \"Loss/Validation\"]],\n",
        "        \"Accuracy\": [\"Multiline\", [\"Accuracy/Train\", \"Accuracy/Validation\"]],\n",
        "    },\n",
        "}\n",
        "\n",
        "writer = SummaryWriter(log_dir=unique_log_dir)\n",
        "writer.add_custom_scalars(layout)\n",
        "\n",
        "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
        "    best_valid_accuracy = 0.0\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        training_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        model.train()\n",
        "\n",
        "        # Initialize variables for train accuracy calculation\n",
        "        num_correct_train = 0\n",
        "        num_examples_train = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            loss = loss_fn(output, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            training_loss += loss.data.item() * inputs.size(0)\n",
        "\n",
        "            # Calculate the number of correct predictions in the current batch\n",
        "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
        "            num_correct_train += torch.sum(correct).item()\n",
        "            num_examples_train += correct.shape[0]\n",
        "\n",
        "        training_loss /= len(train_loader.dataset)\n",
        "        train_accuracy = num_correct_train / num_examples_train\n",
        "\n",
        "        model.eval()\n",
        "        num_correct = 0\n",
        "        num_examples = 0\n",
        "\n",
        "        for batch in val_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            output = model(inputs)\n",
        "            targets = targets.to(device)\n",
        "            loss = loss_fn(output, targets)\n",
        "            valid_loss += loss.data.item() * inputs.size(0)\n",
        "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
        "\n",
        "            num_correct += torch.sum(correct).item()\n",
        "            num_examples += correct.shape[0]\n",
        "\n",
        "        valid_loss /= len(val_loader.dataset)\n",
        "        valid_accuracy = num_correct / num_examples\n",
        "\n",
        "        # Get the current learning rate from the optimizer\n",
        "        current_lr = lr_scheduler.step(valid_accuracy)\n",
        "\n",
        "        print('Epoch: {}, Learning Rate: {}, Training Loss: {:.2f}, Training Accuracy: {:.2f}, Validation Loss: {:.2f}, Validation Accuracy: {:.2f}'.format(epoch, current_lr, training_loss, train_accuracy, valid_loss, valid_accuracy))\n",
        "\n",
        "        # Log training accuracy to TensorBoard\n",
        "        writer.add_scalar('Learning Rate', current_lr, epoch)\n",
        "        writer.add_scalar('Loss/Train', training_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/Train', train_accuracy, epoch)\n",
        "        writer.add_scalar('Loss/Validation', valid_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/Validation', valid_accuracy, epoch)\n",
        "\n",
        "        early_stop = early_stopping.step(valid_accuracy)\n",
        "        if early_stop:\n",
        "            break  # Stop training if early stopping is activated\n",
        "\n",
        "        # Save the best model based on validation accuracy\n",
        "        if valid_accuracy > best_valid_accuracy:\n",
        "            best_valid_accuracy = valid_accuracy\n",
        "            best_model_state = model.state_dict()\n",
        "            # Save the best model state to a file\n",
        "            torch.save(best_model_state, model_path)\n",
        "\n",
        "    print(f\"\\n Model has been saved to {model_path}\")\n",
        "\n",
        "    # Inspect the model\n",
        "    writer.add_graph(model, inputs)\n",
        "    writer.add_figure('Confusion Matrix', plot_confusion_matrix(model, val_loader, device))\n",
        "    # writer.add_figure(f\"Predictions vs. Actuals\", log_predictions_vs_actuals(model, val_loader, device=device, num_batches=1))\n",
        "\n",
        "    # Close the TensorBoard SummaryWriter\n",
        "    writer.close()\n",
        "\n",
        "model = models.mobilenet_v3_large(pretrained=True)\n",
        "\n",
        "# Replace the classifier (fully connected) layer\n",
        "num_features = model.classifier[-4].in_features\n",
        "model.classifier[-4] = nn.Linear(num_features, 500)\n",
        "model.classifier[-1] = nn.Linear(500, 50)\n",
        "\n",
        "lr = 1e-2\n",
        "model.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "    {'params': model.features.parameters(), 'lr': 1e-4},\n",
        "    {'params': model.classifier.parameters(), 'lr': 1e-8}\n",
        "], lr=1e-2)\n",
        "\n",
        "# Use these classes during training\n",
        "patience = 555\n",
        "early_stopping_patience=10\n",
        "early_stopping = EarlyStopping(patience=early_stopping_patience, verbose=True)\n",
        "lr_scheduler = LearningRateScheduler(optimizer, patience=patience, factor=0.1, verbose=True)\n",
        "\n",
        "train(model, optimizer, nn.CrossEntropyLoss(), esc50_train_loader, esc50_val_loader, epochs=50, device=device)\n",
        "\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "test_accuracy = evaluate(model, esc50_test_loader, device=device)\n",
        "print(f\"\\n Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ6I0nmwYM5z",
        "outputId": "42ff41fb-02c1-447d-9338-9474e9cf2f7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Learning Rate: 0.0001, Training Loss: 3.83, Training Accuracy: 0.12, Validation Loss: 3.83, Validation Accuracy: 0.10\n",
            "Epoch: 2, Learning Rate: 0.0001, Training Loss: 3.58, Training Accuracy: 0.30, Validation Loss: 3.53, Validation Accuracy: 0.30\n",
            "Epoch: 3, Learning Rate: 0.0001, Training Loss: 3.34, Training Accuracy: 0.40, Validation Loss: 3.16, Validation Accuracy: 0.43\n",
            "Epoch: 4, Learning Rate: 0.0001, Training Loss: 3.11, Training Accuracy: 0.45, Validation Loss: 2.95, Validation Accuracy: 0.46\n",
            "Epoch: 5, Learning Rate: 0.0001, Training Loss: 2.90, Training Accuracy: 0.49, Validation Loss: 2.77, Validation Accuracy: 0.51\n",
            "Epoch: 6, Learning Rate: 0.0001, Training Loss: 2.69, Training Accuracy: 0.54, Validation Loss: 2.53, Validation Accuracy: 0.50\n",
            "Epoch: 7, Learning Rate: 0.0001, Training Loss: 2.51, Training Accuracy: 0.58, Validation Loss: 2.40, Validation Accuracy: 0.55\n",
            "Epoch: 8, Learning Rate: 0.0001, Training Loss: 2.36, Training Accuracy: 0.61, Validation Loss: 2.33, Validation Accuracy: 0.58\n",
            "Epoch: 9, Learning Rate: 0.0001, Training Loss: 2.20, Training Accuracy: 0.66, Validation Loss: 2.14, Validation Accuracy: 0.60\n",
            "Epoch: 10, Learning Rate: 0.0001, Training Loss: 2.03, Training Accuracy: 0.70, Validation Loss: 2.05, Validation Accuracy: 0.61\n",
            "Epoch: 11, Learning Rate: 0.0001, Training Loss: 1.91, Training Accuracy: 0.72, Validation Loss: 1.89, Validation Accuracy: 0.61\n",
            "Epoch: 12, Learning Rate: 0.0001, Training Loss: 1.76, Training Accuracy: 0.76, Validation Loss: 1.83, Validation Accuracy: 0.64\n",
            "Epoch: 13, Learning Rate: 0.0001, Training Loss: 1.65, Training Accuracy: 0.79, Validation Loss: 1.74, Validation Accuracy: 0.69\n",
            "Epoch: 14, Learning Rate: 0.0001, Training Loss: 1.53, Training Accuracy: 0.80, Validation Loss: 1.72, Validation Accuracy: 0.67\n",
            "Epoch: 15, Learning Rate: 0.0001, Training Loss: 1.42, Training Accuracy: 0.84, Validation Loss: 1.61, Validation Accuracy: 0.69\n",
            "Epoch: 16, Learning Rate: 0.0001, Training Loss: 1.31, Training Accuracy: 0.86, Validation Loss: 1.60, Validation Accuracy: 0.71\n",
            "Epoch: 17, Learning Rate: 0.0001, Training Loss: 1.23, Training Accuracy: 0.86, Validation Loss: 1.45, Validation Accuracy: 0.73\n",
            "Epoch: 18, Learning Rate: 0.0001, Training Loss: 1.09, Training Accuracy: 0.90, Validation Loss: 1.43, Validation Accuracy: 0.73\n",
            "Epoch: 19, Learning Rate: 0.0001, Training Loss: 1.05, Training Accuracy: 0.90, Validation Loss: 1.42, Validation Accuracy: 0.73\n",
            "Epoch: 20, Learning Rate: 0.0001, Training Loss: 0.99, Training Accuracy: 0.90, Validation Loss: 1.40, Validation Accuracy: 0.73\n",
            "Epoch: 21, Learning Rate: 0.0001, Training Loss: 0.90, Training Accuracy: 0.91, Validation Loss: 1.31, Validation Accuracy: 0.73\n",
            "Epoch: 22, Learning Rate: 0.0001, Training Loss: 0.83, Training Accuracy: 0.93, Validation Loss: 1.26, Validation Accuracy: 0.77\n",
            "Epoch: 23, Learning Rate: 0.0001, Training Loss: 0.76, Training Accuracy: 0.95, Validation Loss: 1.26, Validation Accuracy: 0.76\n",
            "Epoch: 24, Learning Rate: 0.0001, Training Loss: 0.70, Training Accuracy: 0.95, Validation Loss: 1.32, Validation Accuracy: 0.72\n",
            "Epoch: 25, Learning Rate: 0.0001, Training Loss: 0.67, Training Accuracy: 0.96, Validation Loss: 1.16, Validation Accuracy: 0.78\n",
            "Epoch: 26, Learning Rate: 0.0001, Training Loss: 0.62, Training Accuracy: 0.96, Validation Loss: 1.25, Validation Accuracy: 0.74\n",
            "Epoch: 27, Learning Rate: 0.0001, Training Loss: 0.59, Training Accuracy: 0.96, Validation Loss: 1.18, Validation Accuracy: 0.76\n",
            "Epoch: 28, Learning Rate: 0.0001, Training Loss: 0.53, Training Accuracy: 0.97, Validation Loss: 1.12, Validation Accuracy: 0.79\n",
            "Epoch: 29, Learning Rate: 0.0001, Training Loss: 0.49, Training Accuracy: 0.97, Validation Loss: 1.27, Validation Accuracy: 0.74\n",
            "Epoch: 30, Learning Rate: 0.0001, Training Loss: 0.46, Training Accuracy: 0.97, Validation Loss: 1.10, Validation Accuracy: 0.77\n",
            "Epoch: 31, Learning Rate: 0.0001, Training Loss: 0.43, Training Accuracy: 0.98, Validation Loss: 1.07, Validation Accuracy: 0.78\n",
            "Epoch: 32, Learning Rate: 0.0001, Training Loss: 0.41, Training Accuracy: 0.98, Validation Loss: 1.15, Validation Accuracy: 0.78\n",
            "Epoch: 33, Learning Rate: 0.0001, Training Loss: 0.35, Training Accuracy: 0.98, Validation Loss: 1.05, Validation Accuracy: 0.78\n",
            "Epoch: 34, Learning Rate: 0.0001, Training Loss: 0.35, Training Accuracy: 0.98, Validation Loss: 1.04, Validation Accuracy: 0.78\n",
            "Epoch: 35, Learning Rate: 0.0001, Training Loss: 0.34, Training Accuracy: 0.98, Validation Loss: 1.17, Validation Accuracy: 0.77\n",
            "Epoch: 36, Learning Rate: 0.0001, Training Loss: 0.33, Training Accuracy: 0.98, Validation Loss: 1.02, Validation Accuracy: 0.80\n",
            "Epoch: 37, Learning Rate: 0.0001, Training Loss: 0.32, Training Accuracy: 0.98, Validation Loss: 1.14, Validation Accuracy: 0.77\n",
            "Epoch: 38, Learning Rate: 0.0001, Training Loss: 0.30, Training Accuracy: 0.99, Validation Loss: 1.02, Validation Accuracy: 0.77\n",
            "Epoch: 39, Learning Rate: 0.0001, Training Loss: 0.27, Training Accuracy: 0.99, Validation Loss: 1.14, Validation Accuracy: 0.77\n",
            "Epoch: 40, Learning Rate: 0.0001, Training Loss: 0.28, Training Accuracy: 0.99, Validation Loss: 1.14, Validation Accuracy: 0.78\n",
            "Epoch: 41, Learning Rate: 0.0001, Training Loss: 0.25, Training Accuracy: 0.98, Validation Loss: 1.02, Validation Accuracy: 0.79\n",
            "Epoch: 42, Learning Rate: 0.0001, Training Loss: 0.26, Training Accuracy: 0.98, Validation Loss: 1.21, Validation Accuracy: 0.75\n",
            "Epoch: 43, Learning Rate: 0.0001, Training Loss: 0.26, Training Accuracy: 0.98, Validation Loss: 1.13, Validation Accuracy: 0.76\n",
            "Epoch: 44, Learning Rate: 0.0001, Training Loss: 0.23, Training Accuracy: 0.99, Validation Loss: 1.10, Validation Accuracy: 0.78\n",
            "Epoch: 45, Learning Rate: 0.0001, Training Loss: 0.22, Training Accuracy: 0.99, Validation Loss: 1.09, Validation Accuracy: 0.77\n",
            "Epoch: 46, Learning Rate: 0.0001, Training Loss: 0.22, Training Accuracy: 0.98, Validation Loss: 1.00, Validation Accuracy: 0.79\n",
            "Epoch: 47, Learning Rate: 0.0001, Training Loss: 0.20, Training Accuracy: 0.99, Validation Loss: 1.12, Validation Accuracy: 0.78\n",
            "Early stopping activated.\n",
            "\n",
            " Model has been saved to tensorboard_logs/2023-11-13_111929_mobilenet_v3_large_without_lr_scheduler/best_model_mobilenet_v3_large_without_lr_scheduler.pth\n",
            "\n",
            " Test Accuracy: 79.00%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "A6ldoxPBLFgm"
      ],
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "224f3eb4eee8451aa9ba52151163032c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36932f9df1804233ba999b7ec0d646b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45d1ea6681c445af8c8937d1a165cba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "660244b55b3c4d928c2258026b94ffaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3649c7014604e919f985460ddbb5b26",
              "IPY_MODEL_8b5e120de2eb4f239730075c838cf5e3",
              "IPY_MODEL_d3fa438ead2e484ea415013088a84c8c"
            ],
            "layout": "IPY_MODEL_36932f9df1804233ba999b7ec0d646b1"
          }
        },
        "8b5e120de2eb4f239730075c838cf5e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6ab51e8a2fb4a71967b57984fc7e8bf",
            "max": 57929264,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45d1ea6681c445af8c8937d1a165cba3",
            "value": 57929264
          }
        },
        "a6ab51e8a2fb4a71967b57984fc7e8bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3fa438ead2e484ea415013088a84c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_224f3eb4eee8451aa9ba52151163032c",
            "placeholder": "​",
            "style": "IPY_MODEL_da85508890414047aee3d9a6b0566c5c",
            "value": " 57.9M/57.9M [00:00&lt;00:00, 91.3MB/s]"
          }
        },
        "da85508890414047aee3d9a6b0566c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcb173e5850e4757bc7ea461e13acb62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3649c7014604e919f985460ddbb5b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f51d3c4a6f374579bade968bc3fb749c",
            "placeholder": "​",
            "style": "IPY_MODEL_dcb173e5850e4757bc7ea461e13acb62",
            "value": "model.safetensors: 100%"
          }
        },
        "f51d3c4a6f374579bade968bc3fb749c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}